{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d59556",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kk43419t4dzT",
    "outputId": "2bf00b6f-d7f6-4a48-a78e-05bdb6b9d7d0"
   },
   "outputs": [],
   "source": [
    "# Google Drive mount for colab\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "# After mounting, /drive/MyDrive/ should appear on the left in Files tab\n",
    "# Go to your own Google Drive, create a /cz4041/ folder, and upload the zip and csv files there\n",
    "# It should appear in the files tab under /drive/MyDrive/cz4041/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92339ead",
   "metadata": {
    "id": "1b36853f-29b3-48d1-a364-19db616a4801"
   },
   "source": [
    "# Data Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca005703",
   "metadata": {
    "id": "aea06625-2d66-4ff1-92cc-6063222bb130"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "import pprint\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostRegressor, RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, ShuffleSplit, KFold,TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import pdb\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "\n",
    "# pandas display options\n",
    "pd.set_option('display.max_columns', 150)\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.set_option('float_format', '{:,.4f}'.format) # All float will be displayed in 4 d.p. with comma to separate thousands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38d7cd4a",
   "metadata": {
    "id": "c9a97915-f943-48ad-9cda-30118a703fd0"
   },
   "outputs": [],
   "source": [
    "# datasets paths\n",
    "path = \"../data\"\n",
    "#path = \"/content/drive/MyDrive/cz4041/\" # path to Google Drive, for colab\n",
    "macro = os.path.join(path, \"macro.csv\")\n",
    "train = os.path.join(path, \"train.zip\")\n",
    "test = os.path.join(path,  \"test.zip\")\n",
    "\n",
    "# place all datasets paths in a datasets dict\n",
    "datasets = {}\n",
    "datasets['macro'] = macro\n",
    "datasets['train'] = train\n",
    "datasets['test'] = test\n",
    "\n",
    "# load dataframes into dfs dict\n",
    "dfs = {}\n",
    "for dataset_name, path in datasets.items():\n",
    "    df = pd.read_csv(path)\n",
    "    dfs[dataset_name] = df\n",
    "\n",
    "# assign to own df variables when you want to use them individually\n",
    "df_macro = dfs['macro']\n",
    "df_train = dfs['train']\n",
    "df_test = dfs['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d50406",
   "metadata": {
    "id": "c0c7eca0-bddb-4322-967b-837c1694db7d",
    "tags": []
   },
   "source": [
    "## Overview of datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220c4bfb",
   "metadata": {
    "id": "329adc68-c5ea-4656-a7dc-26dccbff516d"
   },
   "source": [
    "**Dataset size & Number of distinct datatypes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "790b9c00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "393d7704-805e-49e9-afd5-c17434b341ea",
    "outputId": "9029b006-6c55-4c4c-ad01-7d3ac56956af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Dataset size - macro: (2484, 100) ======\n",
      "Number of distinct datatypes: \n",
      "<class 'numpy.dtype[float64]'>    94\n",
      "<class 'numpy.dtype[object_]'>     4\n",
      "<class 'numpy.dtype[int64]'>       2\n",
      "dtype: int64\n",
      "====== Dataset size - train: (30471, 292) ======\n",
      "Number of distinct datatypes: \n",
      "<class 'numpy.dtype[int64]'>      157\n",
      "<class 'numpy.dtype[float64]'>    119\n",
      "<class 'numpy.dtype[object_]'>     16\n",
      "dtype: int64\n",
      "====== Dataset size - test: (7662, 291) ======\n",
      "Number of distinct datatypes: \n",
      "<class 'numpy.dtype[int64]'>      159\n",
      "<class 'numpy.dtype[float64]'>    116\n",
      "<class 'numpy.dtype[object_]'>     16\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, df in dfs.items():\n",
    "    print(\"====== Dataset size - {}: {} ======\".format(dataset_name , df.shape))\n",
    "    print(\"Number of distinct datatypes: \\n{}\".format(df.dtypes.map(type).value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f67e97",
   "metadata": {},
   "source": [
    "**Prepare dataset for datacleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbf8dbc9",
   "metadata": {
    "id": "0d607c8a-6fa0-4aa6-9fb5-06b317a94dce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38133, 291)\n"
     ]
    }
   ],
   "source": [
    "# Copy train price out to facilitate train & test split later\n",
    "trainPrice = dfs[\"train\"][[\"id\", \"price_doc\"]].copy()\n",
    "\n",
    "# Concat train dataset (minus price_doc) and test dataset for data cleaning\n",
    "trainNoPrice = dfs[\"train\"].drop(\"price_doc\", axis = 1)\n",
    "\n",
    "mergeData = pd.concat([trainNoPrice, dfs[\"test\"]])\n",
    "print(mergeData.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648ee068",
   "metadata": {},
   "source": [
    "## Cleaning of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a85601",
   "metadata": {},
   "source": [
    "**Since we are predicting price, we will want to drop columns that have low correlation value to 'price_doc'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbb7e3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_year                     0.0022\n",
      "kitch_sq                       0.0287\n",
      "school_quota                   0.0140\n",
      "culture_objects_top_25_raion   0.0443\n",
      "full_all                       0.0253\n",
      "male_f                         0.0264\n",
      "female_f                       0.0243\n",
      "16_29_all                      0.0223\n",
      "16_29_male                     0.0231\n",
      "16_29_female                   0.0216\n",
      "build_count_block              0.0315\n",
      "build_count_wood               0.0425\n",
      "build_count_frame              0.0303\n",
      "build_count_panel              0.0201\n",
      "build_count_foam               0.0107\n",
      "build_count_slag               0.0240\n",
      "build_count_mix                0.0330\n",
      "build_count_1921-1945          0.0203\n",
      "build_count_1971-1995          0.0097\n",
      "build_count_after_1995         0.0259\n",
      "cemetery_km                    0.0249\n",
      "ID_railroad_station_walk       0.0218\n",
      "water_km                       0.0266\n",
      "mkad_km                        0.0206\n",
      "big_market_km                  0.0483\n",
      "prom_part_500                  0.0090\n",
      "trc_sqm_500                    0.0004\n",
      "cafe_sum_500_min_price_avg     0.0364\n",
      "cafe_sum_500_max_price_avg     0.0379\n",
      "cafe_avg_price_500             0.0374\n",
      "cafe_count_500_na_price        0.0492\n",
      "big_church_count_500           0.0262\n",
      "church_count_500               0.0147\n",
      "mosque_count_500               0.0185\n",
      "market_count_500               0.0404\n",
      "trc_sqm_1000                   0.0416\n",
      "cafe_count_1000_price_4000     0.0363\n",
      "prom_part_3000                 0.0227\n",
      "cafe_sum_3000_min_price_avg    0.0051\n",
      "cafe_sum_3000_max_price_avg    0.0022\n",
      "cafe_avg_price_3000            0.0033\n",
      "cafe_sum_5000_min_price_avg    0.0322\n",
      "cafe_sum_5000_max_price_avg    0.0333\n",
      "cafe_avg_price_5000            0.0329\n",
      "Name: price_doc, dtype: float64 , 44\n"
     ]
    }
   ],
   "source": [
    "# get the correlation to 'price_doc' in train dataset\n",
    "trainCorr = abs(dfs[\"train\"].corr()[\"price_doc\"])\n",
    "\n",
    "# pick out features that have less than 5% correlation to be dropped\n",
    "threshold = trainCorr <= 0.05\n",
    "lowCorrFeats = trainCorr[threshold]\n",
    "print(lowCorrFeats, \",\", len(lowCorrFeats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5937487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38133, 247)\n"
     ]
    }
   ],
   "source": [
    "# drop\n",
    "mergeData.drop(list(lowCorrFeats.index), axis = 1, inplace = True)\n",
    "print(mergeData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7435590f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38133, 241)\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with 'ID' in name as they do not provide much value\n",
    "\n",
    "IDfeats = [feat for feat in mergeData.columns if \"ID\" in feat]\n",
    "mergeData.drop(IDfeats, axis = 1, inplace = True)\n",
    "print(mergeData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a361d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace data in the following columns\n",
    "mergeData.state.replace({33:3},inplace=True)\n",
    "mergeData[\"material\"].replace(to_replace = 3, value = 1, inplace = True)\n",
    "mergeData[\"full_sq\"].replace(to_replace = 0, value = np.nan, inplace = True)\n",
    "mergeData[\"max_floor\"].replace(to_replace = 0, value = np.nan, inplace = True)\n",
    "mergeData[\"num_room\"].replace(to_replace = 0, value = np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5060939",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33541f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38133, 251)\n"
     ]
    }
   ],
   "source": [
    "# create 'year' and 'year_month' features from 'timestamp'\n",
    "mergeData[\"year\"] = mergeData[\"timestamp\"].apply(lambda x: int(x[0:4]))\n",
    "mergeData[\"year_month\"] = mergeData[\"timestamp\"].apply(lambda x: x[0:7])\\\n",
    "\n",
    "# create 'living_area_ratio', 'non_living_area' and 'non_living_area_ratio' from 'life_sq' and 'full_sq'\n",
    "mergeData[\"living_area_ratio\"] = mergeData[\"life_sq\"] / mergeData[\"full_sq\"]\n",
    "mergeData[\"non_living_area\"] = mergeData[\"full_sq\"] - mergeData[\"life_sq\"]\n",
    "mergeData[\"non_living_area_ratio\"] = mergeData[\"non_living_area\"] / mergeData[\"full_sq\"]\n",
    "\n",
    "# create 'room_area_avg' from 'life_sq' and 'num_room'\n",
    "mergeData[\"room_area_avg\"] = mergeData[\"life_sq\"] / mergeData[\"num_room\"]\n",
    "\n",
    "# create 'relative_floor' from 'floor' and 'max_floor'\n",
    "mergeData[\"relative_floor\"] = mergeData[\"floor\"] / mergeData[\"max_floor\"]\n",
    "\n",
    "# create 'sub_area_building_height_avg' from 'sub_area' and 'max_floor'\n",
    "sub_area_building_avg = mergeData.groupby('sub_area').agg({'max_floor':np.mean}).reset_index().rename(columns={'max_floor':'sub_area_building_height_avg'})\n",
    "mergeData = pd.merge(mergeData, sub_area_building_avg, on = ['sub_area'], how = 'left')\n",
    "\n",
    "# create 'sub_area_kremlin_dist_avg' from 'sub_area' and 'kremlin_km'\n",
    "kremlin_dist = mergeData.groupby('sub_area').agg({'kremlin_km':np.nanmean}).reset_index().rename(columns={'kremlin_km':'sub_area_kremlin_dist_avg'})\n",
    "mergeData = pd.merge(mergeData, kremlin_dist, on = ['sub_area'], how = 'left')\n",
    "\n",
    "# create 'sales_year_month' from 'year_month'\n",
    "sales_year_month = mergeData.groupby('year_month').size().reset_index().rename(columns={0:'sales_year_month'})\n",
    "mergeData = pd.merge(mergeData, sales_year_month, on = ['year_month'], how = 'left')\n",
    "\n",
    "print(mergeData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9d14c7",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f9222e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hospital_beds_raion                      17859\n",
      "room_area_avg                            14897\n",
      "state                                    14253\n",
      "max_floor                                10355\n",
      "relative_floor                           10355\n",
      "num_room                                  9586\n",
      "material                                  9572\n",
      "preschool_quota                           8284\n",
      "cafe_sum_1000_max_price_avg               7746\n",
      "cafe_sum_1000_min_price_avg               7746\n",
      "cafe_avg_price_1000                       7746\n",
      "living_area_ratio                         7562\n",
      "non_living_area_ratio                     7562\n",
      "non_living_area                           7562\n",
      "life_sq                                   7559\n",
      "build_count_brick                         6209\n",
      "raion_build_count_with_builddate_info     6209\n",
      "build_count_before_1920                   6209\n",
      "build_count_monolith                      6209\n",
      "build_count_1946-1970                     6209\n",
      "raion_build_count_with_material_info      6209\n",
      "cafe_sum_1500_min_price_avg               5020\n",
      "cafe_sum_1500_max_price_avg               5020\n",
      "cafe_avg_price_1500                       5020\n",
      "cafe_avg_price_2000                       2149\n",
      "cafe_sum_2000_max_price_avg               2149\n",
      "cafe_sum_2000_min_price_avg               2149\n",
      "prom_part_5000                             270\n",
      "floor                                      167\n",
      "metro_min_walk                              59\n",
      "metro_km_walk                               59\n",
      "railroad_station_walk_min                   59\n",
      "railroad_station_walk_km                    59\n",
      "product_type                                33\n",
      "green_part_2000                             19\n",
      "full_sq                                      3\n",
      "dtype: int64\n",
      "\r\n",
      "Missing Values Count: 36\n"
     ]
    }
   ],
   "source": [
    "# find out columns that have missing values\n",
    "missing_vals = ((mergeData.isna().sum()))\n",
    "missing_vals.sort_values(ascending = False, inplace = True)\n",
    "print(missing_vals[missing_vals > 0])\n",
    "print(\"\\r\\nMissing Values Count: \" + str(len(missing_vals[missing_vals > 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6d3790f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hospital_beds_raion                     0.4683\n",
      "room_area_avg                           0.3907\n",
      "state                                   0.3738\n",
      "max_floor                               0.2715\n",
      "relative_floor                          0.2715\n",
      "num_room                                0.2514\n",
      "material                                0.2510\n",
      "preschool_quota                         0.2172\n",
      "cafe_sum_1000_max_price_avg             0.2031\n",
      "cafe_sum_1000_min_price_avg             0.2031\n",
      "cafe_avg_price_1000                     0.2031\n",
      "living_area_ratio                       0.1983\n",
      "non_living_area_ratio                   0.1983\n",
      "non_living_area                         0.1983\n",
      "life_sq                                 0.1982\n",
      "build_count_brick                       0.1628\n",
      "raion_build_count_with_builddate_info   0.1628\n",
      "build_count_before_1920                 0.1628\n",
      "build_count_monolith                    0.1628\n",
      "build_count_1946-1970                   0.1628\n",
      "raion_build_count_with_material_info    0.1628\n",
      "cafe_sum_1500_min_price_avg             0.1316\n",
      "cafe_sum_1500_max_price_avg             0.1316\n",
      "cafe_avg_price_1500                     0.1316\n",
      "cafe_avg_price_2000                     0.0564\n",
      "cafe_sum_2000_max_price_avg             0.0564\n",
      "cafe_sum_2000_min_price_avg             0.0564\n",
      "prom_part_5000                          0.0071\n",
      "floor                                   0.0044\n",
      "metro_min_walk                          0.0015\n",
      "metro_km_walk                           0.0015\n",
      "railroad_station_walk_min               0.0015\n",
      "railroad_station_walk_km                0.0015\n",
      "product_type                            0.0009\n",
      "green_part_2000                         0.0005\n",
      "full_sq                                 0.0001\n",
      "dtype: float64\n",
      "\r\n",
      "Missing Values Count: 36\n"
     ]
    }
   ],
   "source": [
    "# get the missing values in percentage\n",
    "missing_vals_pct = ((mergeData.isna().sum()) / len(mergeData))\n",
    "missing_vals_pct.sort_values(ascending = False, inplace = True)\n",
    "print(missing_vals_pct[missing_vals_pct > 0])\n",
    "print(\"\\r\\nMissing Values Count: \" + str(len(missing_vals_pct[missing_vals_pct > 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1868cbf6",
   "metadata": {},
   "source": [
    "**Median Imputation for missing values lesser or equal to 30%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aca0ce83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['max_floor', 'relative_floor', 'num_room', 'material',\n",
      "       'preschool_quota', 'cafe_sum_1000_max_price_avg',\n",
      "       'cafe_sum_1000_min_price_avg', 'cafe_avg_price_1000',\n",
      "       'living_area_ratio', 'non_living_area_ratio', 'non_living_area',\n",
      "       'life_sq', 'build_count_brick', 'raion_build_count_with_builddate_info',\n",
      "       'build_count_before_1920', 'build_count_monolith',\n",
      "       'build_count_1946-1970', 'raion_build_count_with_material_info',\n",
      "       'cafe_sum_1500_min_price_avg', 'cafe_sum_1500_max_price_avg',\n",
      "       'cafe_avg_price_1500', 'cafe_avg_price_2000',\n",
      "       'cafe_sum_2000_max_price_avg', 'cafe_sum_2000_min_price_avg',\n",
      "       'prom_part_5000', 'floor', 'metro_min_walk', 'metro_km_walk',\n",
      "       'railroad_station_walk_min', 'railroad_station_walk_km', 'product_type',\n",
      "       'green_part_2000', 'full_sq'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(missing_vals_pct[(missing_vals_pct > 0) & (missing_vals_pct <= 0.3000)].index)\n",
    "\n",
    "for feat in missing_vals_pct[(missing_vals_pct > 0) & (missing_vals_pct <= 0.3000)].index:\n",
    "    try:\n",
    "        mergeData[feat].fillna(mergeData[feat].median(), inplace = True)\n",
    "    except:\n",
    "        mergeData[feat].fillna(mergeData[feat].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "067c3c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hospital_beds_raion   0.4683\n",
      "room_area_avg         0.3907\n",
      "state                 0.3738\n",
      "dtype: float64\n",
      "\r\n",
      "Missing Values Count: 3\n"
     ]
    }
   ],
   "source": [
    "# check remaining missing values in percentage\n",
    "missing_vals_pct = ((mergeData.isna().sum()) / len(mergeData))\n",
    "missing_vals_pct.sort_values(ascending = False, inplace = True)\n",
    "print(missing_vals_pct[missing_vals_pct > 0])\n",
    "print(\"\\r\\nMissing Values Count: \" + str(len(missing_vals_pct[missing_vals_pct > 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c65474",
   "metadata": {},
   "source": [
    "**KNN Imputer for remaining missing values greater than 30%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93e49669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3ec48741e64dec950b11263921feb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sklearn KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "missingCol = list(missing_vals_pct[missing_vals_pct > 0].index)\n",
    "\n",
    "for i in tqdm_notebook(missingCol):\n",
    "    mergeData[i] = imputer.fit_transform(mergeData[[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17aafe7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: float64)\n",
      "\r\n",
      "Missing Values Count: 0\n",
      "\r\n",
      "(38133, 251)\n"
     ]
    }
   ],
   "source": [
    "# check for any remaining missing values\n",
    "missing_vals_pct = ((mergeData.isna().sum()) / len(mergeData))\n",
    "missing_vals_pct.sort_values(ascending = False, inplace = True)\n",
    "print(missing_vals_pct[missing_vals_pct > 0])\n",
    "print(\"\\r\\nMissing Values Count: \" + str(len(missing_vals_pct[missing_vals_pct > 0])))\n",
    "print(\"\\r\\n\" + str(mergeData.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacba8ba",
   "metadata": {},
   "source": [
    "## Prepare Train and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "152c7d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 'trainPrice' dataset from earlier to split 'mergeData' back into train and test datasets\n",
    "xTrain = mergeData[mergeData[\"id\"].isin(trainPrice[\"id\"])]\n",
    "xTrain = pd.merge(xTrain, trainPrice, on = [\"id\"], how = \"inner\")\n",
    "\n",
    "xTest = mergeData[~mergeData[\"id\"].isin(trainPrice[\"id\"])]\n",
    "\n",
    "yTrain = xTrain[\"price_doc\"].apply(lambda j: np.log1p(j))\n",
    "train_id = xTrain['id']\n",
    "xTrain.drop(columns = [\"id\", \"timestamp\", \"price_doc\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3267ae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and cross-validation\n",
    "x_tr, x_cv, y_tr, y_cv = train_test_split(xTrain, yTrain, test_size=0.15,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2580f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wehweh\\AppData\\Local\\Temp/ipykernel_7216/3056538181.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_cv[cat] = x_cv[cat].map(lambda s: '<unknown>' if s not in le.classes_ else s)\n",
      "C:\\Users\\wehweh\\AppData\\Local\\Temp/ipykernel_7216/3056538181.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_tr[cat] = le.transform(x_tr[cat])\n",
      "C:\\Users\\wehweh\\AppData\\Local\\Temp/ipykernel_7216/3056538181.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_cv[cat] = le.transform(x_cv[cat])\n",
      "C:\\Users\\wehweh\\AppData\\Local\\Temp/ipykernel_7216/3056538181.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_tr[num] = (x_tr[num] - min)/(max-min)\n",
      "C:\\Users\\wehweh\\AppData\\Local\\Temp/ipykernel_7216/3056538181.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_cv[num] = (x_cv[num] - min)/(max-min)\n"
     ]
    }
   ],
   "source": [
    "# process categorical ('object') and numerical (non 'object') type data using label encoder\n",
    "\n",
    "categoricals = xTrain.select_dtypes(include = [\"object\"]).copy()\n",
    "numericals = xTrain.select_dtypes(exclude = [\"object\"])\n",
    "\n",
    "# categoricals\n",
    "for cat in categoricals:\n",
    "  le = preprocessing.LabelEncoder()\n",
    "  le.fit(x_tr[cat])\n",
    "\n",
    "  x_cv[cat] = x_cv[cat].map(lambda s: '<unknown>' if s not in le.classes_ else s)\n",
    "  le.classes_ = np.append(le.classes_, '<unknown>')\n",
    "\n",
    "  x_tr[cat] = le.transform(x_tr[cat])\n",
    "  x_cv[cat] = le.transform(x_cv[cat])\n",
    "\n",
    "# numericals\n",
    "for num in numericals:\n",
    "  min = x_tr[num].min()\n",
    "  max = x_tr[num].max()\n",
    "  x_tr[num] = (x_tr[num] - min)/(max-min)\n",
    "  x_cv[num] = (x_cv[num] - min)/(max-min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25d1100f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# check any null values\n",
    "print(x_tr.isnull().values.any())\n",
    "print(x_cv.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327dd4c5",
   "metadata": {},
   "source": [
    "# Testing the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1738f156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result array\n",
    "resArr = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184d73b0",
   "metadata": {},
   "source": [
    "## 1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d5ddec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (after feature selection): (25900, 28)\n",
      "Test (after feature selection) : (4571, 28)\n"
     ]
    }
   ],
   "source": [
    "# Select best features\n",
    "sel = SelectFromModel(RandomForestRegressor(n_jobs = -1, max_depth = 10))\n",
    "sel.fit(x_tr, y_tr)\n",
    "\n",
    "trainFiltered = sel.transform(x_tr)\n",
    "testFiltered = sel.transform(x_cv)\n",
    "\n",
    "print(\"Train (after feature selection): \" + str(trainFiltered.shape))\n",
    "print(\"Test (after feature selection) : \" + str(testFiltered.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3407b7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2, estimator=RandomForestRegressor(), n_iter=15,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [10, 11, 12, 13, 14, 15],\n",
       "                                        'n_estimators': [50, 100, 150, 200, 250,\n",
       "                                                         300]},\n",
       "                   verbose=10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define parameter distributions to use for tuning\n",
    "paramDist = {\n",
    "    'n_estimators': [50, 100, 150, 200, 250, 300],\n",
    "    'max_depth': [10, 11, 12, 13, 14, 15]\n",
    "}\n",
    "\n",
    "# use RandomizedSearchCV to determine best values for parameters\n",
    "randomSearchModel = RandomizedSearchCV(RandomForestRegressor(), param_distributions = paramDist, verbose = 10, n_jobs = -1, cv = 2, n_iter = 15)\n",
    "randomSearchModel.fit(trainFiltered, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e467659d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter values: \n",
      "{'n_estimators': 300, 'max_depth': 15}\n",
      "\r\n",
      "Best Score: \n",
      "0.39347805872935376\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameter values: \")\n",
    "print(randomSearchModel.best_params_)\n",
    "print(\"\\r\\nBest Score: \")\n",
    "print(randomSearchModel.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dcd4191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=15, n_estimators=300, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune the Model with the best hyperparameters\n",
    "rfrModel = RandomForestRegressor(\n",
    "    n_estimators = randomSearchModel.best_params_['n_estimators'],\n",
    "    max_depth = randomSearchModel.best_params_['max_depth'],\n",
    "    random_state = 42,\n",
    "    n_jobs = -1\n",
    ")\n",
    "rfrModel.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3ae97fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Train\n",
      "MSE : 0.0878\n",
      "RMSE: 0.2962\n"
     ]
    }
   ],
   "source": [
    "# predict on train data\n",
    "yPred = rfrModel.predict(x_tr)\n",
    "trainMse = mean_squared_error(y_tr, yPred)\n",
    "print(\"Predict Train\")\n",
    "print(\"MSE : %.4f\" % trainMse)\n",
    "print(\"RMSE: %.4f\" % sqrt(trainMse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e1ffe42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Test\n",
      "MSE : 0.2250\n",
      "RMSE: 0.4743\n"
     ]
    }
   ],
   "source": [
    "# predict on test data\n",
    "yPred = rfrModel.predict(x_cv)\n",
    "testMse = mean_squared_error(y_cv, yPred)\n",
    "print(\"Predict Test\")\n",
    "print(\"MSE : %.4f\" % testMse)\n",
    "print(\"RMSE: %.4f\" % sqrt(testMse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06fb1aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to result array\n",
    "resArr.append([\"Random Forest\", str(\"%.4f\" % trainMse), str(\"%.4f\" % testMse), str(\"%.4f\" % sqrt(trainMse)), str(\"%.4f\" % sqrt(testMse))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae8021a",
   "metadata": {},
   "source": [
    "###  Predict on test.csv test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "938af5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do prep: process.. run pred\n",
    "testRF = xTest.copy()\n",
    "test_id = testRF['id']\n",
    "testRF.drop(['id', 'timestamp'], axis = 1, inplace = True)\n",
    "\n",
    "# process datatype\n",
    "categoricals = xTrain.select_dtypes(include = [\"object\"]).copy()\n",
    "numericals = xTrain.select_dtypes(exclude = [\"object\"])\n",
    "\n",
    "for c in categoricals:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(xTrain[c])\n",
    "\n",
    "    testRF[c] = testRF[c].map(lambda s: \"<unknown>\" if s not in le.classes_ else s)\n",
    "    le.classes_ = np.append(le.classes_, \"<unknown>\")\n",
    "\n",
    "    testRF[c] = le.transform(testRF[c])\n",
    "\n",
    "for n in numericals:\n",
    "    min = xTrain[n].min()\n",
    "    max = xTrain[n].max()\n",
    "\n",
    "    testRF[n] = (testRF[n] - min) / (max - min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed5c871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using random forest model\n",
    "test_pred = rfrModel.predict(testRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba4fb84",
   "metadata": {},
   "source": [
    "### Output File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e921a48",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>material</th>\n",
       "      <th>num_room</th>\n",
       "      <th>state</th>\n",
       "      <th>product_type</th>\n",
       "      <th>sub_area</th>\n",
       "      <th>area_m</th>\n",
       "      <th>raion_popul</th>\n",
       "      <th>green_zone_part</th>\n",
       "      <th>indust_part</th>\n",
       "      <th>children_preschool</th>\n",
       "      <th>preschool_quota</th>\n",
       "      <th>preschool_education_centers_raion</th>\n",
       "      <th>children_school</th>\n",
       "      <th>school_education_centers_raion</th>\n",
       "      <th>school_education_centers_top_20_raion</th>\n",
       "      <th>hospital_beds_raion</th>\n",
       "      <th>healthcare_centers_raion</th>\n",
       "      <th>university_top_20_raion</th>\n",
       "      <th>sport_objects_raion</th>\n",
       "      <th>additional_education_raion</th>\n",
       "      <th>culture_objects_top_25</th>\n",
       "      <th>shopping_centers_raion</th>\n",
       "      <th>office_raion</th>\n",
       "      <th>thermal_power_plant_raion</th>\n",
       "      <th>incineration_raion</th>\n",
       "      <th>oil_chemistry_raion</th>\n",
       "      <th>radiation_raion</th>\n",
       "      <th>railroad_terminal_raion</th>\n",
       "      <th>big_market_raion</th>\n",
       "      <th>nuclear_reactor_raion</th>\n",
       "      <th>detention_facility_raion</th>\n",
       "      <th>young_all</th>\n",
       "      <th>young_male</th>\n",
       "      <th>young_female</th>\n",
       "      <th>work_all</th>\n",
       "      <th>work_male</th>\n",
       "      <th>work_female</th>\n",
       "      <th>ekder_all</th>\n",
       "      <th>ekder_male</th>\n",
       "      <th>ekder_female</th>\n",
       "      <th>0_6_all</th>\n",
       "      <th>0_6_male</th>\n",
       "      <th>0_6_female</th>\n",
       "      <th>7_14_all</th>\n",
       "      <th>7_14_male</th>\n",
       "      <th>7_14_female</th>\n",
       "      <th>0_17_all</th>\n",
       "      <th>0_17_male</th>\n",
       "      <th>0_17_female</th>\n",
       "      <th>0_13_all</th>\n",
       "      <th>0_13_male</th>\n",
       "      <th>0_13_female</th>\n",
       "      <th>raion_build_count_with_material_info</th>\n",
       "      <th>build_count_brick</th>\n",
       "      <th>build_count_monolith</th>\n",
       "      <th>raion_build_count_with_builddate_info</th>\n",
       "      <th>build_count_before_1920</th>\n",
       "      <th>build_count_1946-1970</th>\n",
       "      <th>metro_min_avto</th>\n",
       "      <th>metro_km_avto</th>\n",
       "      <th>metro_min_walk</th>\n",
       "      <th>metro_km_walk</th>\n",
       "      <th>kindergarten_km</th>\n",
       "      <th>school_km</th>\n",
       "      <th>park_km</th>\n",
       "      <th>green_zone_km</th>\n",
       "      <th>industrial_km</th>\n",
       "      <th>water_treatment_km</th>\n",
       "      <th>incineration_km</th>\n",
       "      <th>railroad_station_walk_km</th>\n",
       "      <th>railroad_station_walk_min</th>\n",
       "      <th>...</th>\n",
       "      <th>sport_count_1500</th>\n",
       "      <th>market_count_1500</th>\n",
       "      <th>green_part_2000</th>\n",
       "      <th>prom_part_2000</th>\n",
       "      <th>office_count_2000</th>\n",
       "      <th>office_sqm_2000</th>\n",
       "      <th>trc_count_2000</th>\n",
       "      <th>trc_sqm_2000</th>\n",
       "      <th>cafe_count_2000</th>\n",
       "      <th>cafe_sum_2000_min_price_avg</th>\n",
       "      <th>cafe_sum_2000_max_price_avg</th>\n",
       "      <th>cafe_avg_price_2000</th>\n",
       "      <th>cafe_count_2000_na_price</th>\n",
       "      <th>cafe_count_2000_price_500</th>\n",
       "      <th>cafe_count_2000_price_1000</th>\n",
       "      <th>cafe_count_2000_price_1500</th>\n",
       "      <th>cafe_count_2000_price_2500</th>\n",
       "      <th>cafe_count_2000_price_4000</th>\n",
       "      <th>cafe_count_2000_price_high</th>\n",
       "      <th>big_church_count_2000</th>\n",
       "      <th>church_count_2000</th>\n",
       "      <th>mosque_count_2000</th>\n",
       "      <th>leisure_count_2000</th>\n",
       "      <th>sport_count_2000</th>\n",
       "      <th>market_count_2000</th>\n",
       "      <th>green_part_3000</th>\n",
       "      <th>office_count_3000</th>\n",
       "      <th>office_sqm_3000</th>\n",
       "      <th>trc_count_3000</th>\n",
       "      <th>trc_sqm_3000</th>\n",
       "      <th>cafe_count_3000</th>\n",
       "      <th>cafe_count_3000_na_price</th>\n",
       "      <th>cafe_count_3000_price_500</th>\n",
       "      <th>cafe_count_3000_price_1000</th>\n",
       "      <th>cafe_count_3000_price_1500</th>\n",
       "      <th>cafe_count_3000_price_2500</th>\n",
       "      <th>cafe_count_3000_price_4000</th>\n",
       "      <th>cafe_count_3000_price_high</th>\n",
       "      <th>big_church_count_3000</th>\n",
       "      <th>church_count_3000</th>\n",
       "      <th>mosque_count_3000</th>\n",
       "      <th>leisure_count_3000</th>\n",
       "      <th>sport_count_3000</th>\n",
       "      <th>market_count_3000</th>\n",
       "      <th>green_part_5000</th>\n",
       "      <th>prom_part_5000</th>\n",
       "      <th>office_count_5000</th>\n",
       "      <th>office_sqm_5000</th>\n",
       "      <th>trc_count_5000</th>\n",
       "      <th>trc_sqm_5000</th>\n",
       "      <th>cafe_count_5000</th>\n",
       "      <th>cafe_count_5000_na_price</th>\n",
       "      <th>cafe_count_5000_price_500</th>\n",
       "      <th>cafe_count_5000_price_1000</th>\n",
       "      <th>cafe_count_5000_price_1500</th>\n",
       "      <th>cafe_count_5000_price_2500</th>\n",
       "      <th>cafe_count_5000_price_4000</th>\n",
       "      <th>cafe_count_5000_price_high</th>\n",
       "      <th>big_church_count_5000</th>\n",
       "      <th>church_count_5000</th>\n",
       "      <th>mosque_count_5000</th>\n",
       "      <th>leisure_count_5000</th>\n",
       "      <th>sport_count_5000</th>\n",
       "      <th>market_count_5000</th>\n",
       "      <th>year</th>\n",
       "      <th>year_month</th>\n",
       "      <th>living_area_ratio</th>\n",
       "      <th>non_living_area</th>\n",
       "      <th>non_living_area_ratio</th>\n",
       "      <th>room_area_avg</th>\n",
       "      <th>relative_floor</th>\n",
       "      <th>sub_area_building_height_avg</th>\n",
       "      <th>sub_area_kremlin_dist_avg</th>\n",
       "      <th>sales_year_month</th>\n",
       "      <th>price_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30471</th>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.7174</td>\n",
       "      <td>0.1598</td>\n",
       "      <td>0.0788</td>\n",
       "      <td>0.7300</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8462</td>\n",
       "      <td>0.7784</td>\n",
       "      <td>0.9286</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4483</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1739</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7549</td>\n",
       "      <td>0.7727</td>\n",
       "      <td>0.7360</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.7399</td>\n",
       "      <td>0.7597</td>\n",
       "      <td>0.4517</td>\n",
       "      <td>0.3794</td>\n",
       "      <td>0.4886</td>\n",
       "      <td>0.7300</td>\n",
       "      <td>0.7443</td>\n",
       "      <td>0.7145</td>\n",
       "      <td>0.7784</td>\n",
       "      <td>0.8013</td>\n",
       "      <td>0.7544</td>\n",
       "      <td>0.7581</td>\n",
       "      <td>0.7767</td>\n",
       "      <td>0.7383</td>\n",
       "      <td>0.7505</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>0.7297</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3690</td>\n",
       "      <td>0.9134</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0916</td>\n",
       "      <td>0.5195</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0858</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.1774</td>\n",
       "      <td>0.1943</td>\n",
       "      <td>0.1943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1081</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2014</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3493</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1951</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2510</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0652</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0642</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.5839</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.5248</td>\n",
       "      <td>0.3324</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>5,143,394.3119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30472</th>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.1039</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1111</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.5810</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.1673</td>\n",
       "      <td>0.1024</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.0581</td>\n",
       "      <td>0.0581</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>0.0281</td>\n",
       "      <td>0.0929</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>0.3334</td>\n",
       "      <td>0.3132</td>\n",
       "      <td>0.2205</td>\n",
       "      <td>0.2205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6541</td>\n",
       "      <td>0.0724</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.2449</td>\n",
       "      <td>0.2619</td>\n",
       "      <td>0.2554</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4946</td>\n",
       "      <td>0.2642</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0504</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.5839</td>\n",
       "      <td>0.9937</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.7023</td>\n",
       "      <td>0.3214</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>8,385,081.7318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30473</th>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.5584</td>\n",
       "      <td>0.0746</td>\n",
       "      <td>0.4327</td>\n",
       "      <td>0.3268</td>\n",
       "      <td>0.1872</td>\n",
       "      <td>0.5385</td>\n",
       "      <td>0.3378</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3192</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4483</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.0496</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3331</td>\n",
       "      <td>0.3246</td>\n",
       "      <td>0.3422</td>\n",
       "      <td>0.5647</td>\n",
       "      <td>0.5570</td>\n",
       "      <td>0.5722</td>\n",
       "      <td>0.5869</td>\n",
       "      <td>0.4967</td>\n",
       "      <td>0.6329</td>\n",
       "      <td>0.3268</td>\n",
       "      <td>0.3151</td>\n",
       "      <td>0.3394</td>\n",
       "      <td>0.3378</td>\n",
       "      <td>0.3339</td>\n",
       "      <td>0.3419</td>\n",
       "      <td>0.3374</td>\n",
       "      <td>0.3301</td>\n",
       "      <td>0.3451</td>\n",
       "      <td>0.3315</td>\n",
       "      <td>0.3233</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.3335</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5172</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.2929</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>0.2425</td>\n",
       "      <td>0.1711</td>\n",
       "      <td>0.1462</td>\n",
       "      <td>0.1462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3243</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.5431</td>\n",
       "      <td>0.1873</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0811</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.1786</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>0.1903</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0458</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0727</td>\n",
       "      <td>0.2593</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6180</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0431</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3072</td>\n",
       "      <td>0.4720</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0337</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.2234</td>\n",
       "      <td>0.0677</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.0815</td>\n",
       "      <td>0.0988</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0662</td>\n",
       "      <td>0.0840</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0943</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.5837</td>\n",
       "      <td>0.9935</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.2586</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>5,319,183.4959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30474</th>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.2208</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.3062</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.1673</td>\n",
       "      <td>0.1024</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.0964</td>\n",
       "      <td>0.0964</td>\n",
       "      <td>0.1096</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.1185</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.1012</td>\n",
       "      <td>0.2470</td>\n",
       "      <td>0.4165</td>\n",
       "      <td>0.4165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4163</td>\n",
       "      <td>0.0533</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4689</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2882</td>\n",
       "      <td>0.0511</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.5846</td>\n",
       "      <td>0.9939</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.3331</td>\n",
       "      <td>0.3632</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>6,224,422.7045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30475</th>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.2208</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.5810</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.1673</td>\n",
       "      <td>0.1024</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0964</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.3489</td>\n",
       "      <td>0.3243</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5127</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0541</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.2449</td>\n",
       "      <td>0.2619</td>\n",
       "      <td>0.2554</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5607</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4462</td>\n",
       "      <td>0.2381</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.5825</td>\n",
       "      <td>0.9894</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.7023</td>\n",
       "      <td>0.3214</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>5,086,824.6624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30476</th>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.3549</td>\n",
       "      <td>0.4017</td>\n",
       "      <td>0.4572</td>\n",
       "      <td>0.1957</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.3846</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1454</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2609</td>\n",
       "      <td>0.0426</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1966</td>\n",
       "      <td>0.1947</td>\n",
       "      <td>0.1986</td>\n",
       "      <td>0.3976</td>\n",
       "      <td>0.4815</td>\n",
       "      <td>0.3160</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>0.2373</td>\n",
       "      <td>0.2933</td>\n",
       "      <td>0.1957</td>\n",
       "      <td>0.1918</td>\n",
       "      <td>0.1999</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.1947</td>\n",
       "      <td>0.1987</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2006</td>\n",
       "      <td>0.1963</td>\n",
       "      <td>0.1928</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.2560</td>\n",
       "      <td>0.0551</td>\n",
       "      <td>0.1751</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.2118</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.0283</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.1994</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>0.2104</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1892</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1578</td>\n",
       "      <td>0.6733</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.5540</td>\n",
       "      <td>0.2703</td>\n",
       "      <td>0.2629</td>\n",
       "      <td>0.0404</td>\n",
       "      <td>0.3189</td>\n",
       "      <td>0.3294</td>\n",
       "      <td>0.3253</td>\n",
       "      <td>0.0429</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0573</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.2963</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1811</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>0.5254</td>\n",
       "      <td>0.2424</td>\n",
       "      <td>0.4152</td>\n",
       "      <td>0.0865</td>\n",
       "      <td>0.1092</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0.1165</td>\n",
       "      <td>0.0885</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0471</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1685</td>\n",
       "      <td>0.4102</td>\n",
       "      <td>0.2142</td>\n",
       "      <td>0.3911</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4965</td>\n",
       "      <td>0.2291</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>0.1785</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>0.2626</td>\n",
       "      <td>0.3878</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1523</td>\n",
       "      <td>0.1680</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1226</td>\n",
       "      <td>0.5642</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.5839</td>\n",
       "      <td>0.9937</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.5676</td>\n",
       "      <td>0.4846</td>\n",
       "      <td>0.0964</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>8,524,798.8675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30477</th>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.1948</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.4546</td>\n",
       "      <td>0.0963</td>\n",
       "      <td>0.7112</td>\n",
       "      <td>0.4287</td>\n",
       "      <td>0.3315</td>\n",
       "      <td>0.3846</td>\n",
       "      <td>0.3646</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1547</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2174</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3948</td>\n",
       "      <td>0.3776</td>\n",
       "      <td>0.4131</td>\n",
       "      <td>0.4616</td>\n",
       "      <td>0.4733</td>\n",
       "      <td>0.4503</td>\n",
       "      <td>0.3843</td>\n",
       "      <td>0.3151</td>\n",
       "      <td>0.4197</td>\n",
       "      <td>0.4287</td>\n",
       "      <td>0.3999</td>\n",
       "      <td>0.4597</td>\n",
       "      <td>0.3646</td>\n",
       "      <td>0.3560</td>\n",
       "      <td>0.3736</td>\n",
       "      <td>0.3909</td>\n",
       "      <td>0.3755</td>\n",
       "      <td>0.4072</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.3798</td>\n",
       "      <td>0.4185</td>\n",
       "      <td>0.4762</td>\n",
       "      <td>0.1898</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.4759</td>\n",
       "      <td>0.0620</td>\n",
       "      <td>0.3290</td>\n",
       "      <td>0.0544</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.3345</td>\n",
       "      <td>0.2631</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0811</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.2884</td>\n",
       "      <td>0.4772</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.1351</td>\n",
       "      <td>0.0471</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.1929</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1973</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.0741</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3412</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.1061</td>\n",
       "      <td>0.1109</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.4268</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0307</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1032</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0331</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0283</td>\n",
       "      <td>0.0780</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.5839</td>\n",
       "      <td>0.9937</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.6719</td>\n",
       "      <td>0.2395</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>4,379,101.7587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30478</th>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1121</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3568</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>0.3171</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.3928</td>\n",
       "      <td>0.1383</td>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.0281</td>\n",
       "      <td>0.0301</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0246</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.1673</td>\n",
       "      <td>0.1024</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0868</td>\n",
       "      <td>0.0868</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>0.0658</td>\n",
       "      <td>0.0680</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.1435</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.4931</td>\n",
       "      <td>0.4931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4942</td>\n",
       "      <td>0.1061</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1438</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3860</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4051</td>\n",
       "      <td>0.3929</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0732</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.5839</td>\n",
       "      <td>0.9937</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.4895</td>\n",
       "      <td>0.2961</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>4,280,957.4817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30479</th>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.1169</td>\n",
       "      <td>0.0948</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.0755</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>0.0927</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.0654</td>\n",
       "      <td>0.0642</td>\n",
       "      <td>0.0741</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>0.0717</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0795</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.0645</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0.0659</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>0.7338</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1032</td>\n",
       "      <td>0.0699</td>\n",
       "      <td>0.0883</td>\n",
       "      <td>0.0883</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.1502</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.1121</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>0.3474</td>\n",
       "      <td>0.0932</td>\n",
       "      <td>0.0932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4290</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1747</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5162</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5666</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.5838</td>\n",
       "      <td>0.9934</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.3672</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>3,546,071.6535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30480</th>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.5810</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.1673</td>\n",
       "      <td>0.1024</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>0.1679</td>\n",
       "      <td>0.1228</td>\n",
       "      <td>0.0718</td>\n",
       "      <td>0.0718</td>\n",
       "      <td>0.0847</td>\n",
       "      <td>0.0456</td>\n",
       "      <td>0.1453</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1166</td>\n",
       "      <td>0.3946</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6516</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2073</td>\n",
       "      <td>0.2207</td>\n",
       "      <td>0.2151</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3716</td>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.5825</td>\n",
       "      <td>0.9894</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.7023</td>\n",
       "      <td>0.3214</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>4,674,646.3897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       full_sq  life_sq  floor  max_floor  material  num_room  state  \\\n",
       "30471   0.0071   0.0028 0.0260     0.0690    0.0000    0.0000 0.6667   \n",
       "30472   0.0147   0.0040 0.1039     0.1379    0.0000    0.1111 0.0000   \n",
       "30473   0.0074   0.0034 0.0390     0.0345    0.2000    0.0556 0.3333   \n",
       "30474   0.0116   0.0048 0.2208     0.1379    0.0000    0.0556 0.6667   \n",
       "30475   0.0073   0.0053 0.2208     0.1379    0.0000    0.0000 0.0000   \n",
       "30476   0.0089   0.0040 0.2727     0.0000    0.0000    0.0000 0.0000   \n",
       "30477   0.0071   0.0040 0.1948     0.1379    0.0000    0.0000 0.0000   \n",
       "30478   0.0079   0.0040 0.0649     0.1121    0.0000    0.0000 0.3568   \n",
       "30479   0.0083   0.0038 0.1169     0.0948    0.8000    0.0556 0.3333   \n",
       "30480   0.0079   0.0058 0.0909     0.1810    0.0000    0.0000 0.0000   \n",
       "\n",
       "       product_type  sub_area  area_m  raion_popul  green_zone_part  \\\n",
       "30471             0        38  0.1180       0.7174           0.1598   \n",
       "30472             1       103  0.1150       0.0059           0.5810   \n",
       "30473             0        84  0.0386       0.5584           0.0746   \n",
       "30474             1       105  0.0952       0.0187           0.3062   \n",
       "30475             1       103  0.1150       0.0059           0.5810   \n",
       "30476             1        24  0.0370       0.3549           0.4017   \n",
       "30477             1       124  0.0453       0.4546           0.0963   \n",
       "30478             1       102  0.3171       0.0286           0.3928   \n",
       "30479             0       136  0.0649       0.0755           0.0584   \n",
       "30480             1       103  0.1150       0.0059           0.5810   \n",
       "\n",
       "       indust_part  children_preschool  preschool_quota  \\\n",
       "30471       0.0788              0.7300           1.0000   \n",
       "30472       0.0136              0.0052           0.2416   \n",
       "30473       0.4327              0.3268           0.1872   \n",
       "30474       0.0338              0.0165           0.2416   \n",
       "30475       0.0136              0.0052           0.2416   \n",
       "30476       0.4572              0.1957           0.1276   \n",
       "30477       0.7112              0.4287           0.3315   \n",
       "30478       0.1383              0.0253           0.2416   \n",
       "30479       0.0695              0.0691           0.0927   \n",
       "30480       0.0136              0.0052           0.2416   \n",
       "\n",
       "       preschool_education_centers_raion  children_school  \\\n",
       "30471                             0.8462           0.7784   \n",
       "30472                             0.0000           0.0051   \n",
       "30473                             0.5385           0.3378   \n",
       "30474                             0.0000           0.0159   \n",
       "30475                             0.0000           0.0051   \n",
       "30476                             0.3846           0.1967   \n",
       "30477                             0.3846           0.3646   \n",
       "30478                             0.0000           0.0244   \n",
       "30479                             0.0769           0.0608   \n",
       "30480                             0.0000           0.0051   \n",
       "\n",
       "       school_education_centers_raion  school_education_centers_top_20_raion  \\\n",
       "30471                          0.9286                                 0.5000   \n",
       "30472                          0.0000                                 0.0000   \n",
       "30473                          0.5000                                 0.0000   \n",
       "30474                          0.0000                                 0.0000   \n",
       "30475                          0.0000                                 0.0000   \n",
       "30476                          0.3571                                 0.0000   \n",
       "30477                          0.3571                                 0.0000   \n",
       "30478                          0.0000                                 0.0000   \n",
       "30479                          0.0714                                 0.0000   \n",
       "30480                          0.0000                                 0.0000   \n",
       "\n",
       "       hospital_beds_raion  healthcare_centers_raion  university_top_20_raion  \\\n",
       "30471               0.2462                    0.1667                   0.0000   \n",
       "30472               0.2462                    0.0000                   0.0000   \n",
       "30473               0.3192                    0.5000                   0.0000   \n",
       "30474               0.2462                    0.0000                   0.0000   \n",
       "30475               0.2462                    0.0000                   0.0000   \n",
       "30476               0.1454                    0.5000                   0.0000   \n",
       "30477               0.1547                    0.3333                   0.0000   \n",
       "30478               0.2462                    0.0000                   0.0000   \n",
       "30479               0.0412                    0.1667                   0.0000   \n",
       "30480               0.2462                    0.0000                   0.0000   \n",
       "\n",
       "       sport_objects_raion  additional_education_raion  \\\n",
       "30471               0.4483                      0.2500   \n",
       "30472               0.0000                      0.0000   \n",
       "30473               0.4483                      0.0000   \n",
       "30474               0.0000                      0.1250   \n",
       "30475               0.0000                      0.0000   \n",
       "30476               0.6207                      0.0625   \n",
       "30477               0.1379                      0.1875   \n",
       "30478               0.0345                      0.0000   \n",
       "30479               0.0000                      0.0000   \n",
       "30480               0.0000                      0.0000   \n",
       "\n",
       "       culture_objects_top_25  shopping_centers_raion  office_raion  \\\n",
       "30471                       0                  0.1739        0.0284   \n",
       "30472                       0                  0.0435        0.0000   \n",
       "30473                       0                  0.0870        0.0496   \n",
       "30474                       0                  0.0000        0.0000   \n",
       "30475                       0                  0.0435        0.0000   \n",
       "30476                       0                  0.2609        0.0426   \n",
       "30477                       0                  0.2174        0.0071   \n",
       "30478                       0                  0.0000        0.0071   \n",
       "30479                       0                  0.0435        0.0071   \n",
       "30480                       0                  0.0435        0.0000   \n",
       "\n",
       "       thermal_power_plant_raion  incineration_raion  oil_chemistry_raion  \\\n",
       "30471                          0                   0                    0   \n",
       "30472                          0                   0                    0   \n",
       "30473                          1                   0                    1   \n",
       "30474                          0                   0                    0   \n",
       "30475                          0                   0                    0   \n",
       "30476                          0                   0                    0   \n",
       "30477                          0                   0                    0   \n",
       "30478                          0                   0                    0   \n",
       "30479                          0                   0                    0   \n",
       "30480                          0                   0                    0   \n",
       "\n",
       "       radiation_raion  railroad_terminal_raion  big_market_raion  \\\n",
       "30471                0                        0                 0   \n",
       "30472                0                        0                 0   \n",
       "30473                1                        0                 0   \n",
       "30474                0                        0                 0   \n",
       "30475                0                        0                 0   \n",
       "30476                1                        0                 0   \n",
       "30477                0                        0                 0   \n",
       "30478                0                        0                 1   \n",
       "30479                0                        0                 0   \n",
       "30480                0                        0                 0   \n",
       "\n",
       "       nuclear_reactor_raion  detention_facility_raion  young_all  young_male  \\\n",
       "30471                      0                         0     0.7549      0.7727   \n",
       "30472                      0                         0     0.0052      0.0052   \n",
       "30473                      0                         0     0.3331      0.3246   \n",
       "30474                      0                         0     0.0163      0.0164   \n",
       "30475                      0                         0     0.0052      0.0052   \n",
       "30476                      0                         0     0.1966      0.1947   \n",
       "30477                      0                         0     0.3948      0.3776   \n",
       "30478                      0                         0     0.0249      0.0250   \n",
       "30479                      0                         0     0.0649      0.0654   \n",
       "30480                      0                         0     0.0052      0.0052   \n",
       "\n",
       "       young_female  work_all  work_male  work_female  ekder_all  ekder_male  \\\n",
       "30471        0.7360    0.7500     0.7399       0.7597     0.4517      0.3794   \n",
       "30472        0.0051    0.0058     0.0063       0.0054     0.0055      0.0046   \n",
       "30473        0.3422    0.5647     0.5570       0.5722     0.5869      0.4967   \n",
       "30474        0.0162    0.0184     0.0197       0.0171     0.0174      0.0146   \n",
       "30475        0.0051    0.0058     0.0063       0.0054     0.0055      0.0046   \n",
       "30476        0.1986    0.3976     0.4815       0.3160     0.2743      0.2373   \n",
       "30477        0.4131    0.4616     0.4733       0.4503     0.3843      0.3151   \n",
       "30478        0.0248    0.0281     0.0301       0.0262     0.0267      0.0223   \n",
       "30479        0.0642    0.0741     0.0771       0.0711     0.0717      0.0564   \n",
       "30480        0.0051    0.0058     0.0063       0.0054     0.0055      0.0046   \n",
       "\n",
       "       ekder_female  0_6_all  0_6_male  0_6_female  7_14_all  7_14_male  \\\n",
       "30471        0.4886   0.7300    0.7443      0.7145    0.7784     0.8013   \n",
       "30472        0.0060   0.0052    0.0053      0.0052    0.0051     0.0051   \n",
       "30473        0.6329   0.3268    0.3151      0.3394    0.3378     0.3339   \n",
       "30474        0.0189   0.0165    0.0165      0.0165    0.0159     0.0160   \n",
       "30475        0.0060   0.0052    0.0053      0.0052    0.0051     0.0051   \n",
       "30476        0.2933   0.1957    0.1918      0.1999    0.1967     0.1947   \n",
       "30477        0.4197   0.4287    0.3999      0.4597    0.3646     0.3560   \n",
       "30478        0.0289   0.0253    0.0252      0.0252    0.0244     0.0246   \n",
       "30479        0.0795   0.0691    0.0694      0.0686    0.0608     0.0618   \n",
       "30480        0.0060   0.0052    0.0053      0.0052    0.0051     0.0051   \n",
       "\n",
       "       7_14_female  0_17_all  0_17_male  0_17_female  0_13_all  0_13_male  \\\n",
       "30471       0.7544    0.7581     0.7767       0.7383    0.7505     0.7700   \n",
       "30472       0.0050    0.0053     0.0053       0.0052    0.0052     0.0052   \n",
       "30473       0.3419    0.3374     0.3301       0.3451    0.3315     0.3233   \n",
       "30474       0.0158    0.0165     0.0166       0.0163    0.0162     0.0162   \n",
       "30475       0.0050    0.0053     0.0053       0.0052    0.0052     0.0052   \n",
       "30476       0.1987    0.1975     0.1945       0.2006    0.1963     0.1928   \n",
       "30477       0.3736    0.3909     0.3755       0.4072    0.3985     0.3798   \n",
       "30478       0.0241    0.0253     0.0255       0.0250    0.0248     0.0248   \n",
       "30479       0.0596    0.0647     0.0645       0.0649    0.0650     0.0659   \n",
       "30480       0.0050    0.0053     0.0053       0.0052    0.0052     0.0052   \n",
       "\n",
       "       0_13_female  raion_build_count_with_material_info  build_count_brick  \\\n",
       "30471       0.7297                                1.0000             0.3690   \n",
       "30472       0.0051                                0.1673             0.1024   \n",
       "30473       0.3403                                0.3333             0.3825   \n",
       "30474       0.0161                                0.1673             0.1024   \n",
       "30475       0.0051                                0.1673             0.1024   \n",
       "30476       0.2000                                0.1750             0.2560   \n",
       "30477       0.4185                                0.4762             0.1898   \n",
       "30478       0.0247                                0.1673             0.1024   \n",
       "30479       0.0641                                0.7333             0.3825   \n",
       "30480       0.0051                                0.1673             0.1024   \n",
       "\n",
       "       build_count_monolith  raion_build_count_with_builddate_info  \\\n",
       "30471                0.9134                                 1.0000   \n",
       "30472                0.0472                                 0.1674   \n",
       "30473                0.0236                                 0.3335   \n",
       "30474                0.0472                                 0.1674   \n",
       "30475                0.0472                                 0.1674   \n",
       "30476                0.0551                                 0.1751   \n",
       "30477                0.1260                                 0.4759   \n",
       "30478                0.0472                                 0.1674   \n",
       "30479                0.1417                                 0.7338   \n",
       "30480                0.0472                                 0.1674   \n",
       "\n",
       "       build_count_before_1920  build_count_1946-1970  metro_min_avto  \\\n",
       "30471                   0.0916                 0.5195          0.0205   \n",
       "30472                   0.0000                 0.1645          0.0689   \n",
       "30473                   0.0000                 0.5172          0.0258   \n",
       "30474                   0.0000                 0.1645          0.1291   \n",
       "30475                   0.0000                 0.1645          0.0350   \n",
       "30476                   0.0027                 0.2118          0.0550   \n",
       "30477                   0.0620                 0.3290          0.0544   \n",
       "30478                   0.0000                 0.1645          0.1008   \n",
       "30479                   0.0027                 1.0000          0.1032   \n",
       "30480                   0.0000                 0.1645          0.1679   \n",
       "\n",
       "       metro_km_avto  metro_min_walk  metro_km_walk  kindergarten_km  \\\n",
       "30471         0.0098          0.0124         0.0124           0.0027   \n",
       "30472         0.0460          0.0581         0.0581           0.0410   \n",
       "30473         0.0150          0.0189         0.0189           0.0022   \n",
       "30474         0.0806          0.0964         0.0964           0.1096   \n",
       "30475         0.0230          0.0291         0.0291           0.0309   \n",
       "30476         0.0283          0.0352         0.0352           0.0250   \n",
       "30477         0.0272          0.0344         0.0344           0.0079   \n",
       "30478         0.0687          0.0868         0.0868           0.1025   \n",
       "30479         0.0699          0.0883         0.0883           0.0442   \n",
       "30480         0.1228          0.0718         0.0718           0.0847   \n",
       "\n",
       "       school_km  park_km  green_zone_km  industrial_km  water_treatment_km  \\\n",
       "30471     0.0158   0.0432         0.0310         0.0858              0.0147   \n",
       "30472     0.0281   0.0929         0.0000         0.0528              0.3334   \n",
       "30473     0.0041   0.0530         0.2929         0.0641              0.2425   \n",
       "30474     0.0747   0.1185         0.0128         0.0332              0.1012   \n",
       "30475     0.0260   0.0964         0.2155         0.0252              0.3489   \n",
       "30476     0.0226   0.0362         0.1994         0.0000              0.3048   \n",
       "30477     0.0009   0.0131         0.1818         0.0449              0.3345   \n",
       "30478     0.0658   0.0680         0.0565         0.0060              0.1435   \n",
       "30479     0.0178   0.1502         0.0197         0.1121              0.3460   \n",
       "30480     0.0456   0.1453         0.0000         0.1166              0.3946   \n",
       "\n",
       "       incineration_km  railroad_station_walk_km  railroad_station_walk_min  \\\n",
       "30471           0.1774                    0.1943                     0.1943   \n",
       "30472           0.3132                    0.2205                     0.2205   \n",
       "30473           0.1711                    0.1462                     0.1462   \n",
       "30474           0.2470                    0.4165                     0.4165   \n",
       "30475           0.3243                    0.1506                     0.1506   \n",
       "30476           0.2104                    0.1154                     0.1154   \n",
       "30477           0.2631                    0.0920                     0.0920   \n",
       "30478           0.1695                    0.4931                     0.4931   \n",
       "30479           0.3474                    0.0932                     0.0932   \n",
       "30480           0.3706                    0.0995                     0.0995   \n",
       "\n",
       "       ...  sport_count_1500  market_count_1500  green_part_2000  \\\n",
       "30471  ...            0.1081             0.0000           0.2014   \n",
       "30472  ...            0.0270             0.0000           0.6541   \n",
       "30473  ...            0.3243             0.4286           0.5431   \n",
       "30474  ...            0.0000             0.0000           0.4163   \n",
       "30475  ...            0.0000             0.0000           0.5127   \n",
       "30476  ...            0.1892             0.0000           0.1578   \n",
       "30477  ...            0.0811             0.2857           0.2884   \n",
       "30478  ...            0.0270             0.0000           0.4942   \n",
       "30479  ...            0.0000             0.0000           0.4290   \n",
       "30480  ...            0.0000             0.0000           0.6516   \n",
       "\n",
       "       prom_part_2000  office_count_2000  office_sqm_2000  trc_count_2000  \\\n",
       "30471          0.0210             0.0000           0.0000          0.0000   \n",
       "30472          0.0724             0.0000           0.0000          0.0270   \n",
       "30473          0.1873             0.0240           0.0223          0.0811   \n",
       "30474          0.0533             0.0000           0.0000          0.0000   \n",
       "30475          0.0556             0.0000           0.0000          0.0541   \n",
       "30476          0.6733             0.1120           0.5540          0.2703   \n",
       "30477          0.4772             0.0080           0.0219          0.1351   \n",
       "30478          0.1061             0.0000           0.0000          0.0000   \n",
       "30479          0.0025             0.0000           0.0000          0.0270   \n",
       "30480          0.0036             0.0000           0.0000          0.0270   \n",
       "\n",
       "       trc_sqm_2000  cafe_count_2000  cafe_sum_2000_min_price_avg  \\\n",
       "30471        0.0000           0.0027                       0.3750   \n",
       "30472        0.0020           0.0063                       0.2449   \n",
       "30473        0.0058           0.0251                       0.1786   \n",
       "30474        0.0000           0.0009                       0.0000   \n",
       "30475        0.0090           0.0063                       0.2449   \n",
       "30476        0.2629           0.0404                       0.3189   \n",
       "30477        0.0471           0.0063                       0.1929   \n",
       "30478        0.0000           0.0009                       0.1071   \n",
       "30479        0.0069           0.0018                       0.1875   \n",
       "30480        0.0069           0.0000                       0.2073   \n",
       "\n",
       "       cafe_sum_2000_max_price_avg  cafe_avg_price_2000  \\\n",
       "30471                       0.3333               0.3493   \n",
       "30472                       0.2619               0.2554   \n",
       "30473                       0.1975               0.1903   \n",
       "30474                       0.0000               0.0000   \n",
       "30475                       0.2619               0.2554   \n",
       "30476                       0.3294               0.3253   \n",
       "30477                       0.2000               0.1973   \n",
       "30478                       0.1667               0.1438   \n",
       "30479                       0.1667               0.1747   \n",
       "30480                       0.2207               0.2151   \n",
       "\n",
       "       cafe_count_2000_na_price  cafe_count_2000_price_500  \\\n",
       "30471                    0.0000                     0.0000   \n",
       "30472                    0.0000                     0.0036   \n",
       "30473                    0.0143                     0.0252   \n",
       "30474                    0.0000                     0.0036   \n",
       "30475                    0.0000                     0.0036   \n",
       "30476                    0.0429                     0.0252   \n",
       "30477                    0.0286                     0.0036   \n",
       "30478                    0.0000                     0.0000   \n",
       "30479                    0.0000                     0.0036   \n",
       "30480                    0.0000                     0.0000   \n",
       "\n",
       "       cafe_count_2000_price_1000  cafe_count_2000_price_1500  \\\n",
       "30471                      0.0000                      0.0115   \n",
       "30472                      0.0115                      0.0077   \n",
       "30473                      0.0458                      0.0230   \n",
       "30474                      0.0000                      0.0000   \n",
       "30475                      0.0115                      0.0077   \n",
       "30476                      0.0573                      0.0421   \n",
       "30477                      0.0076                      0.0077   \n",
       "30478                      0.0038                      0.0000   \n",
       "30479                      0.0000                      0.0038   \n",
       "30480                      0.0000                      0.0000   \n",
       "\n",
       "       cafe_count_2000_price_2500  cafe_count_2000_price_4000  \\\n",
       "30471                      0.0000                      0.0000   \n",
       "30472                      0.0059                      0.0000   \n",
       "30473                      0.0118                      0.0000   \n",
       "30474                      0.0000                      0.0000   \n",
       "30475                      0.0059                      0.0000   \n",
       "30476                      0.0412                      0.0123   \n",
       "30477                      0.0000                      0.0000   \n",
       "30478                      0.0000                      0.0000   \n",
       "30479                      0.0000                      0.0000   \n",
       "30480                      0.0000                      0.0000   \n",
       "\n",
       "       cafe_count_2000_price_high  big_church_count_2000  church_count_2000  \\\n",
       "30471                      0.0000                 0.0143             0.0185   \n",
       "30472                      0.0000                 0.0143             0.0185   \n",
       "30473                      0.0000                 0.0286             0.0185   \n",
       "30474                      0.0000                 0.0000             0.0278   \n",
       "30475                      0.0000                 0.0143             0.0185   \n",
       "30476                      0.0625                 0.0143             0.0185   \n",
       "30477                      0.0000                 0.0000             0.0000   \n",
       "30478                      0.0000                 0.0000             0.0185   \n",
       "30479                      0.0000                 0.0000             0.0093   \n",
       "30480                      0.0000                 0.0000             0.0185   \n",
       "\n",
       "       mosque_count_2000  leisure_count_2000  sport_count_2000  \\\n",
       "30471             1.0000              0.0000            0.0926   \n",
       "30472             0.0000              0.0000            0.0185   \n",
       "30473             0.0000              0.0727            0.2593   \n",
       "30474             0.0000              0.0000            0.0000   \n",
       "30475             0.0000              0.0000            0.0556   \n",
       "30476             0.0000              0.0182            0.2963   \n",
       "30477             0.0000              0.0182            0.0741   \n",
       "30478             0.0000              0.0000            0.0185   \n",
       "30479             0.0000              0.0000            0.0000   \n",
       "30480             0.0000              0.0000            0.0000   \n",
       "\n",
       "       market_count_2000  green_part_3000  office_count_3000  office_sqm_3000  \\\n",
       "30471             0.0000           0.1951             0.0000           0.0000   \n",
       "30472             0.0000           0.5317             0.0000           0.0000   \n",
       "30473             0.5000           0.6180             0.0162           0.0352   \n",
       "30474             0.0000           0.4689             0.0000           0.0000   \n",
       "30475             0.0000           0.5607             0.0000           0.0000   \n",
       "30476             0.0000           0.1811             0.1055           0.5254   \n",
       "30477             0.2500           0.3412             0.0061           0.0300   \n",
       "30478             0.0000           0.3860             0.0020           0.0139   \n",
       "30479             0.0000           0.5162             0.0000           0.0000   \n",
       "30480             0.0000           0.5238             0.0000           0.0000   \n",
       "\n",
       "       trc_count_3000  trc_sqm_3000  cafe_count_3000  \\\n",
       "30471          0.0455        0.0275           0.0066   \n",
       "30472          0.0303        0.0083           0.0055   \n",
       "30473          0.0909        0.0147           0.0204   \n",
       "30474          0.0000        0.0000           0.0006   \n",
       "30475          0.0303        0.0083           0.0050   \n",
       "30476          0.2424        0.4152           0.0865   \n",
       "30477          0.1061        0.1109           0.0066   \n",
       "30478          0.0000        0.0000           0.0022   \n",
       "30479          0.0152        0.0064           0.0028   \n",
       "30480          0.0152        0.0064           0.0022   \n",
       "\n",
       "       cafe_count_3000_na_price  cafe_count_3000_price_500  \\\n",
       "30471                    0.0084                     0.0045   \n",
       "30472                    0.0000                     0.0022   \n",
       "30473                    0.0084                     0.0178   \n",
       "30474                    0.0000                     0.0022   \n",
       "30475                    0.0000                     0.0022   \n",
       "30476                    0.1092                     0.0757   \n",
       "30477                    0.0252                     0.0045   \n",
       "30478                    0.0000                     0.0000   \n",
       "30479                    0.0000                     0.0022   \n",
       "30480                    0.0000                     0.0022   \n",
       "\n",
       "       cafe_count_3000_price_1000  cafe_count_3000_price_1500  \\\n",
       "30471                      0.0045                      0.0157   \n",
       "30472                      0.0136                      0.0045   \n",
       "30473                      0.0431                      0.0157   \n",
       "30474                      0.0000                      0.0000   \n",
       "30475                      0.0113                      0.0045   \n",
       "30476                      0.0884                      0.0650   \n",
       "30477                      0.0113                      0.0045   \n",
       "30478                      0.0023                      0.0022   \n",
       "30479                      0.0045                      0.0022   \n",
       "30480                      0.0023                      0.0022   \n",
       "\n",
       "       cafe_count_3000_price_2500  cafe_count_3000_price_4000  \\\n",
       "30471                      0.0000                      0.0000   \n",
       "30472                      0.0038                      0.0000   \n",
       "30473                      0.0075                      0.0000   \n",
       "30474                      0.0000                      0.0000   \n",
       "30475                      0.0038                      0.0000   \n",
       "30476                      0.1165                      0.0885   \n",
       "30477                      0.0000                      0.0000   \n",
       "30478                      0.0038                      0.0088   \n",
       "30479                      0.0038                      0.0000   \n",
       "30480                      0.0038                      0.0000   \n",
       "\n",
       "       cafe_count_3000_price_high  big_church_count_3000  church_count_3000  \\\n",
       "30471                      0.0000                 0.0098             0.0183   \n",
       "30472                      0.0000                 0.0098             0.0305   \n",
       "30473                      0.0000                 0.0196             0.0183   \n",
       "30474                      0.0000                 0.0000             0.0244   \n",
       "30475                      0.0000                 0.0098             0.0244   \n",
       "30476                      0.0435                 0.0294             0.0549   \n",
       "30477                      0.0000                 0.0000             0.0183   \n",
       "30478                      0.0000                 0.0000             0.0244   \n",
       "30479                      0.0000                 0.0000             0.0122   \n",
       "30480                      0.0000                 0.0000             0.0183   \n",
       "\n",
       "       mosque_count_3000  leisure_count_3000  sport_count_3000  \\\n",
       "30471             0.5000              0.0000            0.0700   \n",
       "30472             0.0000              0.0000            0.0700   \n",
       "30473             0.0000              0.0588            0.2200   \n",
       "30474             0.0000              0.0000            0.0000   \n",
       "30475             0.0000              0.0000            0.0600   \n",
       "30476             0.0000              0.0471            0.3600   \n",
       "30477             0.0000              0.0118            0.0500   \n",
       "30478             0.0000              0.0000            0.0100   \n",
       "30479             0.0000              0.0000            0.0000   \n",
       "30480             0.0000              0.0000            0.0000   \n",
       "\n",
       "       market_count_3000  green_part_5000  prom_part_5000  office_count_5000  \\\n",
       "30471             0.0000           0.2510          0.1580             0.0013   \n",
       "30472             0.0000           0.4946          0.2642             0.0025   \n",
       "30473             0.4000           0.3072          0.4720             0.0342   \n",
       "30474             0.0000           0.2882          0.0511             0.0000   \n",
       "30475             0.0000           0.4462          0.2381             0.0013   \n",
       "30476             0.2000           0.1685          0.4102             0.2142   \n",
       "30477             0.2000           0.3140          0.4268             0.0139   \n",
       "30478             0.0000           0.4051          0.3929             0.0038   \n",
       "30479             0.0000           0.5666          0.1249             0.0013   \n",
       "30480             0.0000           0.3716          0.0480             0.0000   \n",
       "\n",
       "       office_sqm_5000  trc_count_5000  trc_sqm_5000  cafe_count_5000  \\\n",
       "30471           0.0030          0.0667        0.0652           0.0072   \n",
       "30472           0.0140          0.0500        0.0504           0.0076   \n",
       "30473           0.0337          0.2167        0.2234           0.0677   \n",
       "30474           0.0000          0.0000        0.0000           0.0019   \n",
       "30475           0.0092          0.0333        0.0439           0.0076   \n",
       "30476           0.3911          0.3333        0.4965           0.2291   \n",
       "30477           0.0307          0.1250        0.1032           0.0197   \n",
       "30478           0.0086          0.0333        0.0732           0.0098   \n",
       "30479           0.0092          0.0250        0.0304           0.0049   \n",
       "30480           0.0000          0.0167        0.0048           0.0068   \n",
       "\n",
       "       cafe_count_5000_na_price  cafe_count_5000_price_500  \\\n",
       "30471                    0.0115                     0.0077   \n",
       "30472                    0.0115                     0.0062   \n",
       "30473                    0.0287                     0.0815   \n",
       "30474                    0.0000                     0.0015   \n",
       "30475                    0.0057                     0.0062   \n",
       "30476                    0.2529                     0.1785   \n",
       "30477                    0.0345                     0.0169   \n",
       "30478                    0.0057                     0.0154   \n",
       "30479                    0.0057                     0.0031   \n",
       "30480                    0.0000                     0.0031   \n",
       "\n",
       "       cafe_count_5000_price_1000  cafe_count_5000_price_1500  \\\n",
       "30471                      0.0062                      0.0125   \n",
       "30472                      0.0123                      0.0062   \n",
       "30473                      0.0988                      0.0655   \n",
       "30474                      0.0000                      0.0016   \n",
       "30475                      0.0123                      0.0078   \n",
       "30476                      0.2083                      0.2231   \n",
       "30477                      0.0216                      0.0187   \n",
       "30478                      0.0093                      0.0078   \n",
       "30479                      0.0093                      0.0047   \n",
       "30480                      0.0123                      0.0078   \n",
       "\n",
       "       cafe_count_5000_price_2500  cafe_count_5000_price_4000  \\\n",
       "30471                      0.0000                      0.0000   \n",
       "30472                      0.0027                      0.0068   \n",
       "30473                      0.0292                      0.0272   \n",
       "30474                      0.0027                      0.0136   \n",
       "30475                      0.0027                      0.0068   \n",
       "30476                      0.2626                      0.3878   \n",
       "30477                      0.0186                      0.0136   \n",
       "30478                      0.0053                      0.0136   \n",
       "30479                      0.0027                      0.0000   \n",
       "30480                      0.0053                      0.0068   \n",
       "\n",
       "       cafe_count_5000_price_high  big_church_count_5000  church_count_5000  \\\n",
       "30471                      0.0000                 0.0066             0.0400   \n",
       "30472                      0.0000                 0.0132             0.0440   \n",
       "30473                      0.0000                 0.0662             0.0840   \n",
       "30474                      0.0000                 0.0000             0.0400   \n",
       "30475                      0.0000                 0.0132             0.0480   \n",
       "30476                      0.4000                 0.1523             0.1680   \n",
       "30477                      0.0000                 0.0331             0.0560   \n",
       "30478                      0.0000                 0.0199             0.0480   \n",
       "30479                      0.0000                 0.0066             0.0280   \n",
       "30480                      0.0000                 0.0132             0.0360   \n",
       "\n",
       "       mosque_count_5000  leisure_count_5000  sport_count_5000  \\\n",
       "30471             0.5000              0.0000            0.0642   \n",
       "30472             0.0000              0.0094            0.0550   \n",
       "30473             0.0000              0.0943            0.3257   \n",
       "30474             0.0000              0.0000            0.0092   \n",
       "30475             0.0000              0.0094            0.0505   \n",
       "30476             0.5000              0.1226            0.5642   \n",
       "30477             0.0000              0.0283            0.0780   \n",
       "30478             0.0000              0.0000            0.0275   \n",
       "30479             0.0000              0.0000            0.0321   \n",
       "30480             0.0000              0.0000            0.0321   \n",
       "\n",
       "       market_count_5000   year  year_month  living_area_ratio  \\\n",
       "30471             0.0476 1.0000          47             0.0056   \n",
       "30472             0.0476 1.0000          47             0.0063   \n",
       "30473             0.5238 1.0000          47             0.0065   \n",
       "30474             0.0000 1.0000          47             0.0061   \n",
       "30475             0.0476 1.0000          47             0.0106   \n",
       "30476             0.3333 1.0000          47             0.0063   \n",
       "30477             0.0952 1.0000          47             0.0063   \n",
       "30478             0.1429 1.0000          47             0.0063   \n",
       "30479             0.0000 1.0000          47             0.0066   \n",
       "30480             0.0000 1.0000          47             0.0106   \n",
       "\n",
       "       non_living_area  non_living_area_ratio  room_area_avg  relative_floor  \\\n",
       "30471           0.5839                 0.9944         0.0083          0.0060   \n",
       "30472           0.5839                 0.9937         0.0074          0.0127   \n",
       "30473           0.5837                 0.9935         0.0050          0.0162   \n",
       "30474           0.5846                 0.9939         0.0072          0.0270   \n",
       "30475           0.5825                 0.9894         0.0160          0.0270   \n",
       "30476           0.5839                 0.9937         0.0074          0.5676   \n",
       "30477           0.5839                 0.9937         0.0074          0.0238   \n",
       "30478           0.5839                 0.9937         0.0074          0.0160   \n",
       "30479           0.5838                 0.9934         0.0057          0.0203   \n",
       "30480           0.5825                 0.9894         0.0174          0.0086   \n",
       "\n",
       "       sub_area_building_height_avg  sub_area_kremlin_dist_avg  \\\n",
       "30471                        0.5248                     0.3324   \n",
       "30472                        0.7023                     0.3214   \n",
       "30473                        0.2586                     0.1357   \n",
       "30474                        0.3331                     0.3632   \n",
       "30475                        0.7023                     0.3214   \n",
       "30476                        0.4846                     0.0964   \n",
       "30477                        0.6719                     0.2395   \n",
       "30478                        0.4895                     0.2961   \n",
       "30479                        0.3672                     0.3590   \n",
       "30480                        0.7023                     0.3214   \n",
       "\n",
       "       sales_year_month      price_doc  \n",
       "30471            0.2309 5,143,394.3119  \n",
       "30472            0.2309 8,385,081.7318  \n",
       "30473            0.2309 5,319,183.4959  \n",
       "30474            0.2309 6,224,422.7045  \n",
       "30475            0.2309 5,086,824.6624  \n",
       "30476            0.2309 8,524,798.8675  \n",
       "30477            0.2309 4,379,101.7587  \n",
       "30478            0.2309 4,280,957.4817  \n",
       "30479            0.2309 3,546,071.6535  \n",
       "30480            0.2309 4,674,646.3897  \n",
       "\n",
       "[10 rows x 250 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# populate price_doc column with predicted prices\n",
    "testRF['price_doc'] = np.expm1(test_pred)\n",
    "testRF.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fdc11157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check output dir\n",
    "if not os.path.exists(\"./output_models\"):\n",
    "    os.mkdir(\"./output_models\")\n",
    "\n",
    "# write id and predicted price_doc columns to csv\n",
    "testRF['id'] = test_id\n",
    "testRF[['id', 'price_doc']].to_csv('./output_models/output_random_forest.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1aee11",
   "metadata": {},
   "source": [
    "## 2. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f77b10e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeRegressor(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [5, 10, 11, 12, 13, 14, 15, 20, 25, 30,\n",
       "                                       35, 40, 45, 50]},\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtModel = DecisionTreeRegressor()\n",
    "\n",
    "# Define 'max_depth' params to use for tuning GridSearchCV\n",
    "paramDepth ={'max_depth' : [5, 10, 11, 12, 13, 14, 15, 20, 25, 30, 35, 40, 45, 50]}\n",
    "\n",
    "gridSearchModel = GridSearchCV(dtModel, param_grid = paramDepth, verbose = 10, cv = 3, n_jobs = -1)\n",
    "gridSearchModel.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c43280e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter values: \n",
      "{'max_depth': 5}\n",
      "\r\n",
      "Best Score: \n",
      "0.3323002293460929\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameter values: \")\n",
    "print(gridSearchModel.best_params_)\n",
    "print(\"\\r\\nBest Score: \")\n",
    "print(gridSearchModel.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca10fc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=5, random_state=42)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune the Model with the best hyperparameters\n",
    "dtModel = DecisionTreeRegressor(\n",
    "    max_depth = gridSearchModel.best_params_['max_depth'],\n",
    "    random_state = 42\n",
    ")\n",
    "dtModel.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25a872f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Train\n",
      "MSE : 0.2341\n",
      "RMSE: 0.4838\n"
     ]
    }
   ],
   "source": [
    "# predict on train data\n",
    "yPred = dtModel.predict(x_tr)\n",
    "trainMse = mean_squared_error(y_tr, yPred)\n",
    "print(\"Predict Train\")\n",
    "print(\"MSE : %.4f\" % trainMse)\n",
    "print(\"RMSE: %.4f\" % sqrt(trainMse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9853e7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Cross Validation\n",
      "MSE : 0.2449\n",
      "RMSE: 0.4949\n"
     ]
    }
   ],
   "source": [
    "# predict on cross validation data\n",
    "yPred = dtModel.predict(x_cv)\n",
    "testMse = mean_squared_error(y_cv, yPred)\n",
    "print(\"Predict Cross Validation\")\n",
    "print(\"MSE : %.4f\" % testMse)\n",
    "print(\"RMSE: %.4f\" % sqrt(testMse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35e1d39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to result array\n",
    "resArr.append([\"Decision Tree\", str(\"%.4f\" % trainMse), str(\"%.4f\" % testMse), str(\"%.4f\" % sqrt(trainMse)), str(\"%.4f\" % sqrt(testMse))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc22cc7",
   "metadata": {},
   "source": [
    "### Predict on test.csv test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ebf3f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same prep: process.. run pred\n",
    "testDT = xTest.copy()\n",
    "testId = testDT[\"id\"]\n",
    "testDT.drop([\"id\", \"timestamp\"], axis = 1, inplace = True)\n",
    "\n",
    "# process datatype\n",
    "categoricals = xTrain.select_dtypes(include = [\"object\"]).copy()\n",
    "numericals = xTrain.select_dtypes(exclude = [\"object\"])\n",
    "\n",
    "for c in categoricals:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(xTrain[c])\n",
    "\n",
    "    testDT[c] = testDT[c].map(lambda s: \"<unknown>\" if s not in le.classes_ else s)\n",
    "    le.classes_ = np.append(le.classes_, \"<unknown>\")\n",
    "\n",
    "    testDT[c] = le.transform(testDT[c])\n",
    "\n",
    "for n in numericals:\n",
    "    min = xTrain[n].min()\n",
    "    max = xTrain[n].max()\n",
    "\n",
    "    testDT[n] = (testDT[n] - min) / (max - min)\n",
    "\n",
    "# predict using decision tree model\n",
    "testPred = dtModel.predict(testDT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4328ecec",
   "metadata": {},
   "source": [
    "**Output prediction to csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3cec5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate price_doc column with predicted prices\n",
    "testDT[\"price_doc\"] = np.expm1(testPred)\n",
    "testDT[\"id\"] = testId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e05f639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check output dir\n",
    "if not os.path.exists(\"./output_models\"):\n",
    "    os.mkdir(\"./output_models\")\n",
    "\n",
    "# write id and predicted price_doc columns to csv\n",
    "testDT[[\"id\", \"price_doc\"]].to_csv(\"./output_models/output_decisiontree.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ba925d",
   "metadata": {},
   "source": [
    "## 3. XGBoost (eXtreme Gradient Boost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1d7628",
   "metadata": {},
   "source": [
    "**Tune Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "126c649c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None,\n",
       "                                          enable_categorical=False, gamma=None,\n",
       "                                          gpu_id=None, importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None,\n",
       "                                          max_delta_step=None, max_depth=None,\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_constraints=...\n",
       "                                          reg_alpha=None, reg_lambda=None,\n",
       "                                          scale_pos_weight=None, subsample=None,\n",
       "                                          tree_method=None,\n",
       "                                          validate_parameters=None,\n",
       "                                          verbosity=None),\n",
       "                   n_iter=15, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.1, 0.25, 0.3,\n",
       "                                                             0.5, 0.75, 0.8,\n",
       "                                                             1],\n",
       "                                        'learning_rate': [0.01, 0.03, 0.05,\n",
       "                                                          0.07, 0.1, 0.13,\n",
       "                                                          0.15],\n",
       "                                        'max_depth': [10, 11, 12, 13, 14, 15],\n",
       "                                        'n_estimators': [50, 100, 150, 200],\n",
       "                                        'subsample': [0.1, 0.3, 0.5, 0.7, 1]},\n",
       "                   verbose=10)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbModel = XGBRegressor(nthread = -1)\n",
    "\n",
    "# define parameter distributions to use for tuning\n",
    "paramDist = {\n",
    "    \"colsample_bytree\": [0.1, 0.25, 0.3, 0.5, 0.75, 0.8, 1],\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05, 0.07, 0.1, 0.13, 0.15],\n",
    "    \"max_depth\": [10, 11, 12, 13, 14, 15],\n",
    "    \"n_estimators\": [50, 100, 150, 200],\n",
    "    \"subsample\": [0.1, 0.3, 0.5, 0.7, 1]\n",
    "}\n",
    "\n",
    "# use RandomizedSearchCV to determine best values for hyperparameters\n",
    "randomSearchModel = RandomizedSearchCV(xgbModel, param_distributions = paramDist, verbose = 10, n_jobs = -1, cv = 2, n_iter = 15)\n",
    "randomSearchModel.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce73e23b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparamter values: \n",
      "{'subsample': 1, 'n_estimators': 100, 'max_depth': 15, 'learning_rate': 0.1, 'colsample_bytree': 0.25}\n",
      "\r\n",
      "Best Score: \n",
      "0.35942363662125304\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparamter values: \")\n",
    "print(randomSearchModel.best_params_)\n",
    "print(\"\\r\\nBest Score: \")\n",
    "print(randomSearchModel.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb979c6",
   "metadata": {},
   "source": [
    "**Use best Hyperparameters in model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03e49f20",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.25,\n",
       "             enable_categorical=False, gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=15, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune Model\n",
    "xgbModel = XGBRegressor(\n",
    "    colsample_bytree = randomSearchModel.best_params_[\"colsample_bytree\"],\n",
    "    learning_rate = randomSearchModel.best_params_[\"learning_rate\"],\n",
    "    max_depth = randomSearchModel.best_params_[\"max_depth\"],\n",
    "    n_estimators = randomSearchModel.best_params_[\"n_estimators\"],\n",
    "    subsample = randomSearchModel.best_params_[\"subsample\"]\n",
    ")\n",
    "# fit model\n",
    "xgbModel.fit(x_tr, y_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a45fac05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Train\n",
      "MSE : 0.0063\n",
      "RMSE: 0.0794\n"
     ]
    }
   ],
   "source": [
    "# predict on train data\n",
    "yPred = xgbModel.predict(x_tr)\n",
    "trainMse = mean_squared_error(y_tr, yPred)\n",
    "print(\"Predict Train\")\n",
    "print(\"MSE : %.4f\" % trainMse)\n",
    "print(\"RMSE: %.4f\" % sqrt(trainMse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b9cf6b7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Cross Validation\n",
      "MSE : 0.2355\n",
      "RMSE: 0.4853\n"
     ]
    }
   ],
   "source": [
    "# predict on cross validation data\n",
    "yPred = xgbModel.predict(x_cv)\n",
    "testMse = mean_squared_error(y_cv, yPred)\n",
    "print(\"Predict Cross Validation\")\n",
    "print(\"MSE : %.4f\" % testMse)\n",
    "print(\"RMSE: %.4f\" % sqrt(testMse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7ddfc29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to result array\n",
    "resArr.append([\"XGBoost\", str(\"%.4f\" % trainMse), str(\"%.4f\" % testMse), str(\"%.4f\" % sqrt(trainMse)), str(\"%.4f\" % sqrt(testMse))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c77a73a",
   "metadata": {},
   "source": [
    "### Predict on test.csv test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30cd62b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same prep: process.. run pred\n",
    "testXGB = xTest.copy()\n",
    "testId = testXGB[\"id\"]\n",
    "testXGB.drop([\"id\", \"timestamp\"], axis = 1, inplace = True)\n",
    "\n",
    "# process datatype\n",
    "categoricals = xTrain.select_dtypes(include = [\"object\"]).copy()\n",
    "numericals = xTrain.select_dtypes(exclude = [\"object\"])\n",
    "\n",
    "for c in categoricals:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(xTrain[c])\n",
    "\n",
    "    testXGB[c] = testXGB[c].map(lambda s: \"<unknown>\" if s not in le.classes_ else s)\n",
    "    le.classes_ = np.append(le.classes_, \"<unknown>\")\n",
    "\n",
    "    testXGB[c] = le.transform(testXGB[c])\n",
    "\n",
    "for n in numericals:\n",
    "    min = xTrain[n].min()\n",
    "    max = xTrain[n].max()\n",
    "\n",
    "    testXGB[n] = (testXGB[n] - min) / (max - min)\n",
    "\n",
    "# predict using xgb model\n",
    "testPred = xgbModel.predict(testXGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040cacb5",
   "metadata": {},
   "source": [
    "**Output prediction to csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "877c721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate price_doc column with predicted prices\n",
    "testXGB[\"price_doc\"] = np.expm1(testPred)\n",
    "testXGB[\"id\"] = testId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80dc0afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check output dir\n",
    "if not os.path.exists(\"./output_models\"):\n",
    "    os.mkdir(\"./output_models\")\n",
    "\n",
    "# write id and predicted price_doc columns to csv\n",
    "testXGB[[\"id\", \"price_doc\"]].to_csv(\"./output_models/output_xgboost.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ff8c01",
   "metadata": {},
   "source": [
    "## 4. SGD (Stochastic Gradient Descent) Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe6f6dd",
   "metadata": {},
   "source": [
    "**Tune Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4be9cc68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=SGDRegressor(), n_iter=15, n_jobs=-1,\n",
       "                   param_distributions={'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0,\n",
       "                                                  10.0, 100.0, 1000.0,\n",
       "                                                  10000.0],\n",
       "                                        'learning_rate': ['optimal'],\n",
       "                                        'loss': ['squared_loss'],\n",
       "                                        'max_iter': [500, 1000, 1500, 2000],\n",
       "                                        'penalty': ['l2']},\n",
       "                   verbose=10)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgdModel = SGDRegressor()\n",
    "\n",
    "# define parameter distributions to use for tuning\n",
    "paramDist = {\n",
    "    \"alpha\": [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4],\n",
    "    \"learning_rate\": ['optimal'],\n",
    "    \"loss\": [\"squared_loss\"],\n",
    "    \"max_iter\": [500, 1000, 1500, 2000],\n",
    "    \"penalty\": [\"l2\"]\n",
    "}\n",
    "\n",
    "# use RandomizedSearchCV to determine best values for hyperparameters\n",
    "randomSearchModel = RandomizedSearchCV(sgdModel, param_distributions = paramDist, verbose = 10, n_jobs = -1, cv=3, n_iter = 15)\n",
    "randomSearchModel.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "252d7c00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparamter values: \n",
      "{'penalty': 'l2', 'max_iter': 1000, 'loss': 'squared_loss', 'learning_rate': 'optimal', 'alpha': 10000.0}\n",
      "\r\n",
      "Best Score: \n",
      "-243.08490046294347\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparamter values: \")\n",
    "print(randomSearchModel.best_params_)\n",
    "print(\"\\r\\nBest Score: \")\n",
    "print(randomSearchModel.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272c465e",
   "metadata": {},
   "source": [
    "**Use best Hyperparameters in model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e48b0519",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=10000.0, learning_rate='optimal')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune Model\n",
    "sgdModel = SGDRegressor(\n",
    "    alpha = randomSearchModel.best_params_[\"alpha\"],\n",
    "    learning_rate = \"optimal\",\n",
    "    loss = \"squared_loss\",\n",
    "    max_iter = randomSearchModel.best_params_[\"max_iter\"],\n",
    "    penalty = \"l2\",\n",
    ")\n",
    "# fit model\n",
    "sgdModel.fit(x_tr, y_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f43745a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Train\n",
      "MSE : 91.1125\n",
      "RMSE: 9.5453\n"
     ]
    }
   ],
   "source": [
    "# predict on train data\n",
    "yPred = sgdModel.predict(x_tr)\n",
    "trainMse = mean_squared_error(y_tr, yPred)\n",
    "print(\"Predict Train\")\n",
    "print(\"MSE : %.4f\" % trainMse)\n",
    "print(\"RMSE: %.4f\" % sqrt(trainMse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b7d9ace",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Cross Validation\n",
      "MSE : 90.4085\n",
      "RMSE: 9.5083\n"
     ]
    }
   ],
   "source": [
    "# predict on cross validation data\n",
    "yPred = sgdModel.predict(x_cv)\n",
    "testMse = mean_squared_error(y_cv, yPred)\n",
    "print(\"Predict Cross Validation\")\n",
    "print(\"MSE : %.4f\" % testMse)\n",
    "print(\"RMSE: %.4f\" % sqrt(testMse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e3d179cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to result array\n",
    "resArr.append([\"SGD\", str(\"%.4f\" % trainMse), str(\"%.4f\" % testMse), str(\"%.4f\" % sqrt(trainMse)), str(\"%.4f\" % sqrt(testMse))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f729604f",
   "metadata": {},
   "source": [
    "### Predict on test.csv test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "55f165f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same prep: process.. run pred\n",
    "testSGD = xTest.copy()\n",
    "testId = testSGD[\"id\"]\n",
    "testSGD.drop([\"id\", \"timestamp\"], axis = 1, inplace = True)\n",
    "\n",
    "# process datatype\n",
    "categoricals = xTrain.select_dtypes(include = [\"object\"]).copy()\n",
    "numericals = xTrain.select_dtypes(exclude = [\"object\"])\n",
    "\n",
    "for c in categoricals:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(xTrain[c])\n",
    "\n",
    "    testSGD[c] = testSGD[c].map(lambda s: \"<unknown>\" if s not in le.classes_ else s)\n",
    "    le.classes_ = np.append(le.classes_, \"<unknown>\")\n",
    "\n",
    "    testSGD[c] = le.transform(testSGD[c])\n",
    "\n",
    "for n in numericals:\n",
    "    min = xTrain[n].min()\n",
    "    max = xTrain[n].max()\n",
    "\n",
    "    testSGD[n] = (testSGD[n] - min) / (max - min)\n",
    "\n",
    "# predict using sgd model\n",
    "testPred = sgdModel.predict(testSGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ae5e24",
   "metadata": {},
   "source": [
    "**Output prediction to csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "22f4e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate price_doc column with predicted prices\n",
    "testSGD[\"price_doc\"] = np.expm1(testPred)\n",
    "testSGD[\"id\"] = testId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4f029173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check output dir\n",
    "if not os.path.exists(\"./output_models\"):\n",
    "    os.mkdir(\"./output_models\")\n",
    "\n",
    "# write id and predicted price_doc columns to csv\n",
    "testSGD[[\"id\", \"price_doc\"]].to_csv(\"./output_models/output_sgd.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f778aeb",
   "metadata": {},
   "source": [
    "## 5. AdaBoost (Adaptive Boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04b2a41",
   "metadata": {},
   "source": [
    "**Tune 'n_estimators' parameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a01e10c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=AdaBoostRegressor(), n_jobs=-1,\n",
       "                   param_distributions={'n_estimators': [50, 100, 150, 200, 250,\n",
       "                                                         300]},\n",
       "                   verbose=10)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adbModel = AdaBoostRegressor()\n",
    "\n",
    "# define 'n_estimators' distributions to use for tuning\n",
    "paramDist = { \"n_estimators\": [50, 100, 150, 200, 250, 300] }\n",
    "\n",
    "# use RandomizedSearchCV to determine best value for 'n_estimators'\n",
    "randomSearchModel = RandomizedSearchCV(adbModel, param_distributions = paramDist, verbose = 10, n_jobs = -1, cv = 3)\n",
    "randomSearchModel.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "de0a2cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 'n_estimators' value: \n",
      "50\n",
      "\r\n",
      "Best Score: \n",
      "-0.4884744829271992\n"
     ]
    }
   ],
   "source": [
    "print(\"Best 'n_estimators' value: \")\n",
    "print(randomSearchModel.best_params_[\"n_estimators\"])\n",
    "print(\"\\r\\nBest Score: \")\n",
    "print(randomSearchModel.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c588c28",
   "metadata": {},
   "source": [
    "**Use best 'n_estimators' value in model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "26608d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune Model\n",
    "adbModel = AdaBoostRegressor(n_estimators = randomSearchModel.best_params_[\"n_estimators\"])\n",
    "# fit model\n",
    "adbModel.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "18afeea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Train\n",
      "MSE : 0.5598\n",
      "RMSE: 0.7482\n"
     ]
    }
   ],
   "source": [
    "# predict on train data\n",
    "yPred = adbModel.predict(x_tr)\n",
    "trainMse = mean_squared_error(y_tr, yPred)\n",
    "print(\"Predict Train\")\n",
    "print(\"MSE : %.4f\" % trainMse)\n",
    "print(\"RMSE: %.4f\" % sqrt(trainMse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8352d49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Cross Validation\n",
      "MSE : 0.5538\n",
      "RMSE: 0.7442\n"
     ]
    }
   ],
   "source": [
    "# predict on cross validation data\n",
    "yPred = adbModel.predict(x_cv)\n",
    "testMse = mean_squared_error(y_cv, yPred)\n",
    "print(\"Predict Cross Validation\")\n",
    "print(\"MSE : %.4f\" % testMse)\n",
    "print(\"RMSE: %.4f\" % sqrt(testMse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5b9c6368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4571"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "83d132d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to result array\n",
    "resArr.append([\"AdaBoost\", str(\"%.4f\" % trainMse), str(\"%.4f\" % testMse), str(\"%.4f\" % sqrt(trainMse)), str(\"%.4f\" % sqrt(testMse))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d39544",
   "metadata": {},
   "source": [
    "### Predict on test.csv test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2508d54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same prep: process.. run pred\n",
    "testAdB = xTest.copy()\n",
    "testId = testAdB[\"id\"]\n",
    "testAdB.drop([\"id\", \"timestamp\"], axis = 1, inplace = True)\n",
    "\n",
    "# process datatype\n",
    "categoricals = xTrain.select_dtypes(include = [\"object\"]).copy()\n",
    "numericals = xTrain.select_dtypes(exclude = [\"object\"])\n",
    "\n",
    "for c in categoricals:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(xTrain[c])\n",
    "\n",
    "    testAdB[c] = testAdB[c].map(lambda s: \"<unknown>\" if s not in le.classes_ else s)\n",
    "    le.classes_ = np.append(le.classes_, \"<unknown>\")\n",
    "\n",
    "    testAdB[c] = le.transform(testAdB[c])\n",
    "\n",
    "for n in numericals:\n",
    "    min = xTrain[n].min()\n",
    "    max = xTrain[n].max()\n",
    "\n",
    "    testAdB[n] = (testAdB[n] - min) / (max - min)\n",
    "\n",
    "# predict using adb model\n",
    "testPred = adbModel.predict(testAdB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8729c664",
   "metadata": {},
   "source": [
    "**Output prediction to csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7e7b63d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate price_doc column with predicted prices\n",
    "testAdB[\"price_doc\"] = np.expm1(testPred)\n",
    "testAdB[\"id\"] = testId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fcf7484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check output dir\n",
    "if not os.path.exists(\"./output_models\"):\n",
    "    os.mkdir(\"./output_models\")\n",
    "\n",
    "# write id and predicted price_doc columns to csv\n",
    "testAdB[[\"id\", \"price_doc\"]].to_csv(\"./output_models/output_adaboost.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59fa221",
   "metadata": {},
   "source": [
    "# 6. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3b47cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_predict(train, test, y_train):\n",
    "    RS=1\n",
    "    np.random.seed(RS)\n",
    "    ROUNDS = 1500 # 1300,1400 all works fine\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            'boosting': 'gbdt',\n",
    "            'learning_rate': 0.01 , #small learn rate, large number of iterations\n",
    "            'verbose': -1,\n",
    "            'num_leaves': 2 ** 5,\n",
    "            'bagging_fraction': 0.95,\n",
    "            'bagging_freq': 1,\n",
    "            'bagging_seed': RS,\n",
    "            'feature_fraction': 0.7,\n",
    "            'feature_fraction_seed': RS,\n",
    "            'max_bin': 100,\n",
    "            'max_depth': 7,\n",
    "            'num_rounds': ROUNDS,\n",
    "    }\n",
    "    train_lgb=lgb.Dataset(train,y_train)\n",
    "    model=lgb.train(params,train_lgb,num_boost_round=ROUNDS)\n",
    "    predict=model.predict(test)\n",
    "#     predict=np.exp(predict)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7a563a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do prep: process.. run pred\n",
    "testLgbm = xTest.copy()\n",
    "test_id = testLgbm['id']\n",
    "testLgbm.drop(['id', 'timestamp'], axis = 1, inplace = True)\n",
    "\n",
    "# process datatype\n",
    "categoricals = xTrain.select_dtypes(include = [\"object\"]).copy()\n",
    "numericals = xTrain.select_dtypes(exclude = [\"object\"])\n",
    "\n",
    "for c in categoricals:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(xTrain[c])\n",
    "\n",
    "    testLgbm[c] = testLgbm[c].map(lambda s: \"<unknown>\" if s not in le.classes_ else s)\n",
    "    le.classes_ = np.append(le.classes_, \"<unknown>\")\n",
    "\n",
    "    testLgbm[c] = le.transform(testLgbm[c])\n",
    "\n",
    "for n in numericals:\n",
    "    min = xTrain[n].min()\n",
    "    max = xTrain[n].max()\n",
    "\n",
    "    testLgbm[n] = (testLgbm[n] - min) / (max - min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a22c2103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Train\n",
      "MSE : 0.1414\n",
      "RMSE: 0.3760\n"
     ]
    }
   ],
   "source": [
    "# predict on train data\n",
    "lgbm_pred = lgbm_predict(x_tr, x_tr, y_tr)\n",
    "trainMse = mean_squared_error(y_tr, lgbm_pred)\n",
    "print(\"Predict Train\")\n",
    "print(\"MSE : %.4f\" % trainMse)\n",
    "print(\"RMSE: %.4f\" % sqrt(trainMse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2bbb2bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Cross Validation\n",
      "MSE : 0.2117\n",
      "RMSE: 0.4601\n"
     ]
    }
   ],
   "source": [
    "# predict on cross validation data\n",
    "lgbm_pred = lgbm_predict(x_tr, x_cv, y_tr)\n",
    "testMse = mean_squared_error(y_cv, lgbm_pred)\n",
    "print(\"Predict Cross Validation\")\n",
    "print(\"MSE : %.4f\" % testMse)\n",
    "print(\"RMSE: %.4f\" % sqrt(testMse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2df1fb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.37145868, 15.52221449, 15.21597236, ..., 15.19071261,\n",
       "       15.74439144, 15.82490189])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "afab6467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to result array\n",
    "resArr.append([\"LightGBM\", str(\"%.4f\" % trainMse), str(\"%.4f\" % testMse), str(\"%.4f\" % sqrt(trainMse)), str(\"%.4f\" % sqrt(testMse))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5f0650",
   "metadata": {},
   "source": [
    "### Predict on test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "343ad38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "lgbm_pred = lgbm_predict(x_tr, testLgbm, y_tr)\n",
    "lgbm_output=pd.DataFrame({'id':test_id,'price_doc':np.expm1(lgbm_pred)})\n",
    "lgbm_output.to_csv('./output_models/output_lgbm.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeb6339",
   "metadata": {},
   "source": [
    "## Test raw data on naive xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2d750cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrainnxgb = dfs[\"train\"].drop([\"id\", \"timestamp\", \"price_doc\"], axis=1).select_dtypes(include=['number','bool','category'])\n",
    "ytrainnxgb = dfs['train']['price_doc'].copy()\n",
    "testnxgb = dfs['test'].drop([\"id\", \"timestamp\"], axis=1).select_dtypes(include=['number','bool','category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e111be9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [       nan 0.59771744        nan 0.58460408 0.60800526 0.58068904\n",
      " 0.59524717 0.59075785 0.57494798 0.5968936  0.5755111  0.57702976\n",
      " 0.57216222 0.56617424 0.58360857 0.57431374 0.56528977        nan\n",
      " 0.58728883 0.59626088]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:47:25] WARNING: c:\\ci\\xgboost-split_1638290375667\\work\\src\\objective\\regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None,\n",
       "                                          enable_categorical=False, eta=0.05,\n",
       "                                          eval_metric='rmse', gamma=0,\n",
       "                                          gpu_id=None, importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None,\n",
       "                                          max_delta_step=None, max_depth=None,\n",
       "                                          min_child_weight=None, missing=...\n",
       "                                          reg_alpha=None, reg_lambda=None,\n",
       "                                          scale_pos_weight=None, subsample=None,\n",
       "                                          tree_method=None, ...),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.55, 0.7, 0.8,\n",
       "                                                             0.85, 0.9, 1,\n",
       "                                                             1.4],\n",
       "                                        'learning_rate': [0.07, 0.08, 0.1, 0.12,\n",
       "                                                          0.15],\n",
       "                                        'max_depth': [2, 3, 4, 5, 6, 8],\n",
       "                                        'min_child_weight': [3, 4, 5, 6],\n",
       "                                        'n_estimators': [200, 220, 240, 300],\n",
       "                                        'subsample': [0.7, 0.8, 0.9, 1]},\n",
       "                   verbose=10)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbModel = XGBRegressor(eta=0.05, nthread = -1, objective='reg:linear',\n",
    "    eval_metric='rmse', gamma=0)\n",
    "\n",
    "# define parameter distributions to use for tuning\n",
    "paramDist = {\n",
    "    \"colsample_bytree\": [0.55, 0.7, 0.8, 0.85, 0.9, 1, 1.4],\n",
    "    \"learning_rate\": [0.07, 0.08, 0.1, 0.12, 0.15],\n",
    "    \"max_depth\": [2, 3, 4, 5, 6, 8],\n",
    "    \"n_estimators\": [200, 220, 240, 300],\n",
    "    \"subsample\": [0.7, 0.8, 0.9, 1],\n",
    "    \"min_child_weight\": [3, 4, 5, 6]\n",
    "}\n",
    "\n",
    "# use RandomizedSearchCV to determine best values for hyperparameters\n",
    "randomSearchModel = RandomizedSearchCV(xgbModel, param_distributions = paramDist, verbose = 10, n_jobs = -1, cv = 2, n_iter = 20)\n",
    "randomSearchModel.fit(xtrainnxgb, ytrainnxgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1463ea04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'learning_rate': randomSearchModel.best_params_[\"learning_rate\"],\n",
    "    'max_depth': randomSearchModel.best_params_[\"max_depth\"],\n",
    "    'min_child_weight': randomSearchModel.best_params_[\"min_child_weight\"],\n",
    "    'subsample': randomSearchModel.best_params_[\"subsample\"],\n",
    "    'n_estimators': randomSearchModel.best_params_[\"n_estimators\"],\n",
    "    'colsample_bytree': randomSearchModel.best_params_[\"colsample_bytree\"],\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 1,\n",
    "    'gamma': 0\n",
    "}\n",
    "\n",
    "xtrainnxgb = dfs[\"train\"]\n",
    "xtrainnxgb=xtrainnxgb[(xtrainnxgb.price_doc>1e6) & (xtrainnxgb.price_doc!=2e6) & (xtrainnxgb.price_doc!=3e6)]\n",
    "xtrainnxgb.loc[(xtrainnxgb.product_type=='Investment') & (xtrainnxgb.build_year<2000),'price_doc']*=0.895 \n",
    "xtrainnxgb.loc[xtrainnxgb.product_type!='Investment','price_doc']*=0.96 #Louis/Andy's magic number\n",
    "\n",
    "ytrainnxgb = xtrainnxgb['price_doc'].copy()\n",
    "xtrainnxgb = xtrainnxgb.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1).select_dtypes(include=['number','bool','category'])\n",
    "testnxgb = dfs['test'].drop([\"id\", \"timestamp\"], axis=1).select_dtypes(include=['number','bool','category'])\n",
    "\n",
    "for c in xtrainnxgb.columns:\n",
    "    if xtrainnxgb[c].dtype == 'object':\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(xtrainnxgb[c].values)) \n",
    "        xtrainnxgb[c] = lbl.transform(list(xtrainnxgb[c].values))\n",
    "        #x_train.drop(c,axis=1,inplace=True)\n",
    "        \n",
    "for c in testnxgb.columns:\n",
    "    if testnxgb[c].dtype == 'object':\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(testnxgb[c].values)) \n",
    "        testnxgb[c] = lbl.transform(list(testnxgb[c].values))\n",
    "        #x_test.drop(c,axis=1,inplace=True)        \n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(xtrainnxgb, ytrainnxgb)\n",
    "dtest = xgb.DMatrix(testnxgb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "471581cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:47:39] WARNING: c:\\ci\\xgboost-split_1638290375667\\work\\src\\objective\\regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[20:47:39] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimators\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:47:39] WARNING: c:\\ci\\xgboost-split_1638290375667\\work\\src\\objective\\regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[20:47:39] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimators\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:47:39] WARNING: c:\\ci\\xgboost-split_1638290375667\\work\\src\\objective\\regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[20:47:39] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimators\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:7745810.66667\ttest-rmse:7749574.16667\n",
      "[50]\ttrain-rmse:1911322.29167\ttest-rmse:2319749.50000\n",
      "[100]\ttrain-rmse:1665874.45833\ttest-rmse:2227683.66667\n",
      "[150]\ttrain-rmse:1532271.00000\ttest-rmse:2195893.83333\n",
      "[200]\ttrain-rmse:1443056.54167\ttest-rmse:2180496.91667\n",
      "[250]\ttrain-rmse:1368558.83333\ttest-rmse:2175366.50000\n",
      "[263]\ttrain-rmse:1351240.45833\ttest-rmse:2175224.41667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_output = xgb.cv(xgb_params, dtrain, num_boost_round=1000, early_stopping_rounds=20,\n",
    "    verbose_eval=50, show_stdv=False)\n",
    "cv_output[['train-rmse-mean', 'test-rmse-mean']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "28aa4b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:48:10] WARNING: c:\\ci\\xgboost-split_1638290375667\\work\\src\\objective\\regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[20:48:10] WARNING: ..\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimators\", \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_boost_rounds = len(cv_output)\n",
    "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round= num_boost_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "916d3ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testId = dfs['test']['id']\n",
    "y_predict = model.predict(dtest)\n",
    "output = pd.DataFrame({'id': testId, 'price_doc': y_predict})\n",
    "output.to_csv(\"./output_models/output_naivexgb.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f1f0ad85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30474</td>\n",
       "      <td>5,251,370.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30475</td>\n",
       "      <td>7,929,659.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30476</td>\n",
       "      <td>5,347,367.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30477</td>\n",
       "      <td>5,808,495.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30478</td>\n",
       "      <td>4,969,001.5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      price_doc\n",
       "0  30474 5,251,370.0000\n",
       "1  30475 7,929,659.5000\n",
       "2  30476 5,347,367.5000\n",
       "3  30477 5,808,495.0000\n",
       "4  30478 4,969,001.5000"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d80b3d8",
   "metadata": {},
   "source": [
    "## Process raw data for testing with LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7e0d127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_process(train, test):\n",
    "    #Remove the bad prices as suggested by Radar\n",
    "    train=train[(train.price_doc>1e6) & (train.price_doc!=2e6) & (train.price_doc!=3e6)]\n",
    "    train.loc[(train.product_type=='Investment') & (train.build_year<=2000),'price_doc']*=0.895 \n",
    "    train.loc[train.product_type!='Investment','price_doc']*=0.96\n",
    "\n",
    "  \n",
    "    id_test = test.id\n",
    "    times=pd.concat([train.timestamp,test.timestamp])\n",
    "    num_train=train.shape[0]\n",
    "    y_train = train[\"price_doc\"]\n",
    "    train.drop(['price_doc'],inplace=True,axis=1)\n",
    "    da=pd.concat([train,test])\n",
    "    da['na_count']=da.isnull().sum(axis=1)\n",
    "    df_cat=None\n",
    "    to_remove=[]\n",
    "    for c in da.columns:\n",
    "        if da[c].dtype=='object':\n",
    "            oh=pd.get_dummies(da[c],prefix=c)\n",
    "            if df_cat is None:\n",
    "                df_cat=oh\n",
    "            else:\n",
    "                df_cat=pd.concat([df_cat,oh],axis=1)\n",
    "            to_remove.append(c)\n",
    "    da.drop(to_remove,inplace=True,axis=1)\n",
    "\n",
    "    #Remove rare features,prevent overfitting\n",
    "    to_remove=[]\n",
    "    if df_cat is not None:\n",
    "        sums=df_cat.sum(axis=0)\n",
    "        to_remove=sums[sums<200].index.values\n",
    "        df_cat=df_cat.loc[:,df_cat.columns.difference(to_remove)]\n",
    "        da = pd.concat([da, df_cat], axis=1)\n",
    "    x_train=da[:num_train].drop(['timestamp','id'],axis=1)\n",
    "    x_test=da[num_train:].drop(['timestamp','id'],axis=1)\n",
    "    #Log transformation, boxcox works better.\n",
    "    y_train=np.log(y_train)\n",
    "    \n",
    "    return x_train, x_test, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "680c5b23",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "lgbm_train = pd.read_csv('../data/train.zip',parse_dates=['timestamp'])\n",
    "lgbm_test = pd.read_csv('../data/test.zip',parse_dates=['timestamp'])\n",
    "lgbmx_train, lgbmx_test, lgbmy_train = lgbm_process(lgbm_train, lgbm_test)\n",
    "id_test =  lgbm_test.id\n",
    "lgbm_pred = lgbm_predict(lgbmx_train, lgbmx_test, lgbmy_train)\n",
    "lgbm_output = pd.DataFrame({'id':id_test,'price_doc':np.expm1(lgbm_pred)})\n",
    "lgbm_output.to_csv('./output_models/lgbm_raw.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e0baf7",
   "metadata": {},
   "source": [
    "**Display Result Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "499297cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model</th>\n",
       "      <th>Train MSE</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Test RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.0878</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.4743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.2449</td>\n",
       "      <td>0.4838</td>\n",
       "      <td>0.4949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.2355</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>0.4853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SGD</td>\n",
       "      <td>91.1125</td>\n",
       "      <td>90.4085</td>\n",
       "      <td>9.5453</td>\n",
       "      <td>9.5083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.5538</td>\n",
       "      <td>0.7482</td>\n",
       "      <td>0.7442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.1414</td>\n",
       "      <td>0.2117</td>\n",
       "      <td>0.3760</td>\n",
       "      <td>0.4601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resdf = pd.DataFrame(resArr, columns = [\"Model\", \"Train MSE\", \"Test MSE\", \"Train RMSE\", \"Test RMSE\"])\n",
    "display(HTML(resdf.to_html(index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c55aa37",
   "metadata": {},
   "source": [
    "**SGD Regressor has an appalling performance with extremely high MSE / RMSE scores**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ce0f5e",
   "metadata": {},
   "source": [
    "## Trying a different approach:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720cfaeb",
   "metadata": {},
   "source": [
    "## Step 1: Split train data into 80-20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4f7c06a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and cross-validation\n",
    "x_tr, x_cv, y_tr, y_cv = train_test_split(xTrain, yTrain, test_size=0.15,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7b1d7a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wehweh\\AppData\\Local\\Temp/ipykernel_7216/707167389.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_cv[c] = x_cv[c].map(lambda s: '<unknown>' if s not in labelEnc.classes_ else s)\n",
      "C:\\Users\\wehweh\\AppData\\Local\\Temp/ipykernel_7216/707167389.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_tr[c] = labelEnc.transform(x_tr[c])\n",
      "C:\\Users\\wehweh\\AppData\\Local\\Temp/ipykernel_7216/707167389.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_cv[c] = labelEnc.transform(x_cv[c])\n",
      "C:\\Users\\wehweh\\AppData\\Local\\Temp/ipykernel_7216/707167389.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_tr[c] = (x_tr[c] - min)/(max-min)\n",
      "C:\\Users\\wehweh\\AppData\\Local\\Temp/ipykernel_7216/707167389.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_cv[c] = (x_cv[c] - min)/(max-min)\n"
     ]
    }
   ],
   "source": [
    "# Effect code categorical variables:\n",
    "\n",
    "num = xTrain.select_dtypes(exclude=['object'])\n",
    "cat = xTrain.select_dtypes(include=['object']).copy()\n",
    "\n",
    "\n",
    "for c in cat:\n",
    "  labelEnc = preprocessing.LabelEncoder()\n",
    "  labelEnc.fit(x_tr[c])\n",
    "\n",
    "  x_cv[c] = x_cv[c].map(lambda s: '<unknown>' if s not in labelEnc.classes_ else s)\n",
    "  labelEnc.classes_ = np.append(labelEnc.classes_, '<unknown>')\n",
    "\n",
    "  x_tr[c] = labelEnc.transform(x_tr[c])\n",
    "  x_cv[c] = labelEnc.transform(x_cv[c])\n",
    "\n",
    "for c in num:\n",
    "  min = x_tr[c].min()\n",
    "  max = x_tr[c].max()\n",
    "\n",
    "  x_tr[c] = (x_tr[c] - min)/(max-min)\n",
    "  x_cv[c] = (x_cv[c] - min)/(max-min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2ae85e",
   "metadata": {},
   "source": [
    "## Step 2: In train set, split the train set into A1 and A2 50-50 split\n",
    "## Then we use A1 to do sampling with replacement to create a1,a2....ak(k samples).\n",
    "## Now we create 'k' models, and train each of our models with these k samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c618e38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1, A2, y_a1, y_a2 = train_test_split(x_tr, y_tr, test_size=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fbbc3587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12950, 249) (12950, 249)\n"
     ]
    }
   ],
   "source": [
    "A1 = A1.to_numpy()\n",
    "A2 = A2.to_numpy()\n",
    "\n",
    "y_a1 = y_a1.to_numpy()\n",
    "y_a2 = y_a2.to_numpy()\n",
    "\n",
    "print(A1.shape, A2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63be74ae",
   "metadata": {},
   "source": [
    "### Generate random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0a61f1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generating_samples(input_, target_):\n",
    "     \n",
    "    s_rows = random.sample(range(len(input_)),int(len(input_)*0.60))  \n",
    "    sample_data = list()\n",
    "    target_data = list()\n",
    "    \n",
    "    for i in s_rows:\n",
    "      sample_data.append(input_[i])\n",
    "        \n",
    "    target_data = target_[s_rows].tolist()\n",
    "    \n",
    "    \n",
    "    \n",
    "    return sample_data, target_data, s_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "746f0535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b91832cb04409fb002dea052d13bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create 200 samples using generating_samples function\n",
    "input_data =[]\n",
    "output_data =[]\n",
    "selected_rows = []\n",
    "\n",
    "f = 200\n",
    "\n",
    "for i in tqdm_notebook(range(f)):\n",
    "    a,b,c = generating_samples(A1, y_a1)\n",
    "    input_data.append(a)\n",
    "    output_data.append(b)\n",
    "    selected_rows.append(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e58cece",
   "metadata": {},
   "source": [
    "## Regression Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c840a09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b18034bc2de4cd9bae61546119ded01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_all_models = list()\n",
    "\n",
    "for i in tqdm_notebook(range(len(input_data))):\n",
    "    \n",
    "    k = np.array(input_data[i])\n",
    "    j = np.array(output_data[i])\n",
    "      \n",
    "    model = DecisionTreeRegressor(max_depth = None)\n",
    "    model.fit(k,j)\n",
    "    \n",
    "    list_all_models.append(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aa6ee9",
   "metadata": {},
   "source": [
    "## Step 3: We pass the A2 set to each k models, then we will get k predictions for A2 for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e2ad4a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_predictions = list()\n",
    "\n",
    "for i in list_all_models:\n",
    "  k_predictions.append(i.predict(A2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "deef463c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12950, 200)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_predictions = np.array(k_predictions)\n",
    "k_predictions = k_predictions.T\n",
    "k_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28247ac3",
   "metadata": {},
   "source": [
    "## Step 4: We then use the k predictions to create a new dataset, and for A2, since we know it's target values, we can use the k predictions to train a meta model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0f1a0e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for train is:  0.22060914184361416\n"
     ]
    }
   ],
   "source": [
    "# Using Linear Regression Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(k_predictions, y_a2)\n",
    "\n",
    "print(\"MSE for train is: \", mean_squared_error(reg.predict(k_predictions), y_a2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6712ca",
   "metadata": {},
   "source": [
    "## Step 5: For the model evaluation, we use the 20% data that we kept as the test set. \n",
    "## Pass that test set to each base model and we will get 'k' predictions. \n",
    "## We then create a new dataset using these k predictions and pass it to our meta model to get the final prediction. We can calculate the models performance score using this final prediction as well as the targets for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c67fe752",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance score for test data is:  0.35790452874302425\n"
     ]
    }
   ],
   "source": [
    "# Testing the Model\n",
    "test_pred = list()\n",
    "\n",
    "for model in list_all_models:\n",
    "  test_pred.append(model.predict(x_cv))\n",
    "\n",
    "test_pred = np.array(test_pred)\n",
    "test_pred = test_pred.T\n",
    "\n",
    "print(\"Model Performance score for test data is: \", reg.score(test_pred, y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9cc22cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23238404920546463\n"
     ]
    }
   ],
   "source": [
    "# Mean Sqaured Error for test data is:\n",
    "\n",
    "mse = mean_squared_error(reg.predict(test_pred), y_cv)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfcc45d",
   "metadata": {},
   "source": [
    "### Predicting the house prices for test.csv file data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "75536dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7662, 249)\n"
     ]
    }
   ],
   "source": [
    "x_test = xTest.copy()\n",
    "test_id = x_test['id']\n",
    "x_test.drop(['id','timestamp'],axis=1,inplace=True)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5e569c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the House prices\n",
    "# Preparing test data:\n",
    "\n",
    "num = xTrain.select_dtypes(exclude=['object'])\n",
    "cat = xTrain.select_dtypes(include=['object']).copy()\n",
    "\n",
    "\n",
    "for c in cat:\n",
    "  labelEnc = preprocessing.LabelEncoder()\n",
    "  labelEnc.fit(xTrain[c])\n",
    "\n",
    "  x_test[c] = x_test[c].map(lambda s: '<unknown>' if s not in labelEnc.classes_ else s)\n",
    "  labelEnc.classes_ = np.append(labelEnc.classes_, '<unknown>')\n",
    "\n",
    "  x_test[c] = labelEnc.transform(x_test[c])\n",
    "\n",
    "for c in num:\n",
    "  min = xTrain[c].min()\n",
    "  max = xTrain[c].max()\n",
    "\n",
    "  x_test[c] = (x_test[c] - min)/(max-min)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e62d8678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the House prices \n",
    "# Testing the Model\n",
    "test_pred = list()\n",
    "\n",
    "for model in list_all_models:\n",
    "  test_pred.append(model.predict(x_test))\n",
    "\n",
    "test_pred = np.array(test_pred)\n",
    "test_pred = test_pred.T\n",
    "pred = reg.predict(test_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5fd05ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>material</th>\n",
       "      <th>num_room</th>\n",
       "      <th>state</th>\n",
       "      <th>product_type</th>\n",
       "      <th>sub_area</th>\n",
       "      <th>area_m</th>\n",
       "      <th>raion_popul</th>\n",
       "      <th>green_zone_part</th>\n",
       "      <th>indust_part</th>\n",
       "      <th>children_preschool</th>\n",
       "      <th>preschool_quota</th>\n",
       "      <th>preschool_education_centers_raion</th>\n",
       "      <th>children_school</th>\n",
       "      <th>school_education_centers_raion</th>\n",
       "      <th>school_education_centers_top_20_raion</th>\n",
       "      <th>hospital_beds_raion</th>\n",
       "      <th>healthcare_centers_raion</th>\n",
       "      <th>university_top_20_raion</th>\n",
       "      <th>sport_objects_raion</th>\n",
       "      <th>additional_education_raion</th>\n",
       "      <th>culture_objects_top_25</th>\n",
       "      <th>shopping_centers_raion</th>\n",
       "      <th>office_raion</th>\n",
       "      <th>thermal_power_plant_raion</th>\n",
       "      <th>incineration_raion</th>\n",
       "      <th>oil_chemistry_raion</th>\n",
       "      <th>radiation_raion</th>\n",
       "      <th>railroad_terminal_raion</th>\n",
       "      <th>big_market_raion</th>\n",
       "      <th>nuclear_reactor_raion</th>\n",
       "      <th>detention_facility_raion</th>\n",
       "      <th>young_all</th>\n",
       "      <th>young_male</th>\n",
       "      <th>young_female</th>\n",
       "      <th>work_all</th>\n",
       "      <th>work_male</th>\n",
       "      <th>work_female</th>\n",
       "      <th>ekder_all</th>\n",
       "      <th>ekder_male</th>\n",
       "      <th>ekder_female</th>\n",
       "      <th>0_6_all</th>\n",
       "      <th>0_6_male</th>\n",
       "      <th>0_6_female</th>\n",
       "      <th>7_14_all</th>\n",
       "      <th>7_14_male</th>\n",
       "      <th>7_14_female</th>\n",
       "      <th>0_17_all</th>\n",
       "      <th>0_17_male</th>\n",
       "      <th>0_17_female</th>\n",
       "      <th>0_13_all</th>\n",
       "      <th>0_13_male</th>\n",
       "      <th>0_13_female</th>\n",
       "      <th>raion_build_count_with_material_info</th>\n",
       "      <th>build_count_brick</th>\n",
       "      <th>build_count_monolith</th>\n",
       "      <th>raion_build_count_with_builddate_info</th>\n",
       "      <th>build_count_before_1920</th>\n",
       "      <th>build_count_1946-1970</th>\n",
       "      <th>metro_min_avto</th>\n",
       "      <th>metro_km_avto</th>\n",
       "      <th>metro_min_walk</th>\n",
       "      <th>metro_km_walk</th>\n",
       "      <th>kindergarten_km</th>\n",
       "      <th>school_km</th>\n",
       "      <th>park_km</th>\n",
       "      <th>green_zone_km</th>\n",
       "      <th>industrial_km</th>\n",
       "      <th>water_treatment_km</th>\n",
       "      <th>incineration_km</th>\n",
       "      <th>railroad_station_walk_km</th>\n",
       "      <th>railroad_station_walk_min</th>\n",
       "      <th>...</th>\n",
       "      <th>sport_count_1500</th>\n",
       "      <th>market_count_1500</th>\n",
       "      <th>green_part_2000</th>\n",
       "      <th>prom_part_2000</th>\n",
       "      <th>office_count_2000</th>\n",
       "      <th>office_sqm_2000</th>\n",
       "      <th>trc_count_2000</th>\n",
       "      <th>trc_sqm_2000</th>\n",
       "      <th>cafe_count_2000</th>\n",
       "      <th>cafe_sum_2000_min_price_avg</th>\n",
       "      <th>cafe_sum_2000_max_price_avg</th>\n",
       "      <th>cafe_avg_price_2000</th>\n",
       "      <th>cafe_count_2000_na_price</th>\n",
       "      <th>cafe_count_2000_price_500</th>\n",
       "      <th>cafe_count_2000_price_1000</th>\n",
       "      <th>cafe_count_2000_price_1500</th>\n",
       "      <th>cafe_count_2000_price_2500</th>\n",
       "      <th>cafe_count_2000_price_4000</th>\n",
       "      <th>cafe_count_2000_price_high</th>\n",
       "      <th>big_church_count_2000</th>\n",
       "      <th>church_count_2000</th>\n",
       "      <th>mosque_count_2000</th>\n",
       "      <th>leisure_count_2000</th>\n",
       "      <th>sport_count_2000</th>\n",
       "      <th>market_count_2000</th>\n",
       "      <th>green_part_3000</th>\n",
       "      <th>office_count_3000</th>\n",
       "      <th>office_sqm_3000</th>\n",
       "      <th>trc_count_3000</th>\n",
       "      <th>trc_sqm_3000</th>\n",
       "      <th>cafe_count_3000</th>\n",
       "      <th>cafe_count_3000_na_price</th>\n",
       "      <th>cafe_count_3000_price_500</th>\n",
       "      <th>cafe_count_3000_price_1000</th>\n",
       "      <th>cafe_count_3000_price_1500</th>\n",
       "      <th>cafe_count_3000_price_2500</th>\n",
       "      <th>cafe_count_3000_price_4000</th>\n",
       "      <th>cafe_count_3000_price_high</th>\n",
       "      <th>big_church_count_3000</th>\n",
       "      <th>church_count_3000</th>\n",
       "      <th>mosque_count_3000</th>\n",
       "      <th>leisure_count_3000</th>\n",
       "      <th>sport_count_3000</th>\n",
       "      <th>market_count_3000</th>\n",
       "      <th>green_part_5000</th>\n",
       "      <th>prom_part_5000</th>\n",
       "      <th>office_count_5000</th>\n",
       "      <th>office_sqm_5000</th>\n",
       "      <th>trc_count_5000</th>\n",
       "      <th>trc_sqm_5000</th>\n",
       "      <th>cafe_count_5000</th>\n",
       "      <th>cafe_count_5000_na_price</th>\n",
       "      <th>cafe_count_5000_price_500</th>\n",
       "      <th>cafe_count_5000_price_1000</th>\n",
       "      <th>cafe_count_5000_price_1500</th>\n",
       "      <th>cafe_count_5000_price_2500</th>\n",
       "      <th>cafe_count_5000_price_4000</th>\n",
       "      <th>cafe_count_5000_price_high</th>\n",
       "      <th>big_church_count_5000</th>\n",
       "      <th>church_count_5000</th>\n",
       "      <th>mosque_count_5000</th>\n",
       "      <th>leisure_count_5000</th>\n",
       "      <th>sport_count_5000</th>\n",
       "      <th>market_count_5000</th>\n",
       "      <th>year</th>\n",
       "      <th>year_month</th>\n",
       "      <th>living_area_ratio</th>\n",
       "      <th>non_living_area</th>\n",
       "      <th>non_living_area_ratio</th>\n",
       "      <th>room_area_avg</th>\n",
       "      <th>relative_floor</th>\n",
       "      <th>sub_area_building_height_avg</th>\n",
       "      <th>sub_area_kremlin_dist_avg</th>\n",
       "      <th>sales_year_month</th>\n",
       "      <th>price_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30471</th>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.7174</td>\n",
       "      <td>0.1598</td>\n",
       "      <td>0.0788</td>\n",
       "      <td>0.7300</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8462</td>\n",
       "      <td>0.7784</td>\n",
       "      <td>0.9286</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4483</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1739</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7549</td>\n",
       "      <td>0.7727</td>\n",
       "      <td>0.7360</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.7399</td>\n",
       "      <td>0.7597</td>\n",
       "      <td>0.4517</td>\n",
       "      <td>0.3794</td>\n",
       "      <td>0.4886</td>\n",
       "      <td>0.7300</td>\n",
       "      <td>0.7443</td>\n",
       "      <td>0.7145</td>\n",
       "      <td>0.7784</td>\n",
       "      <td>0.8013</td>\n",
       "      <td>0.7544</td>\n",
       "      <td>0.7581</td>\n",
       "      <td>0.7767</td>\n",
       "      <td>0.7383</td>\n",
       "      <td>0.7505</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>0.7297</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3690</td>\n",
       "      <td>0.9134</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0916</td>\n",
       "      <td>0.5195</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0858</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.1774</td>\n",
       "      <td>0.1943</td>\n",
       "      <td>0.1943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1081</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2014</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3493</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1951</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2510</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0652</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0642</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.5839</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.5248</td>\n",
       "      <td>0.3324</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>5,247,336.8339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30472</th>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.1039</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1111</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.5810</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.1673</td>\n",
       "      <td>0.1024</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.0581</td>\n",
       "      <td>0.0581</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>0.0281</td>\n",
       "      <td>0.0929</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>0.3334</td>\n",
       "      <td>0.3132</td>\n",
       "      <td>0.2205</td>\n",
       "      <td>0.2205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6541</td>\n",
       "      <td>0.0724</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.2449</td>\n",
       "      <td>0.2619</td>\n",
       "      <td>0.2554</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5317</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4946</td>\n",
       "      <td>0.2642</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0504</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.5839</td>\n",
       "      <td>0.9937</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.7023</td>\n",
       "      <td>0.3214</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>8,183,807.8635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30473</th>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.5584</td>\n",
       "      <td>0.0746</td>\n",
       "      <td>0.4327</td>\n",
       "      <td>0.3268</td>\n",
       "      <td>0.1872</td>\n",
       "      <td>0.5385</td>\n",
       "      <td>0.3378</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3192</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4483</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.0496</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3331</td>\n",
       "      <td>0.3246</td>\n",
       "      <td>0.3422</td>\n",
       "      <td>0.5647</td>\n",
       "      <td>0.5570</td>\n",
       "      <td>0.5722</td>\n",
       "      <td>0.5869</td>\n",
       "      <td>0.4967</td>\n",
       "      <td>0.6329</td>\n",
       "      <td>0.3268</td>\n",
       "      <td>0.3151</td>\n",
       "      <td>0.3394</td>\n",
       "      <td>0.3378</td>\n",
       "      <td>0.3339</td>\n",
       "      <td>0.3419</td>\n",
       "      <td>0.3374</td>\n",
       "      <td>0.3301</td>\n",
       "      <td>0.3451</td>\n",
       "      <td>0.3315</td>\n",
       "      <td>0.3233</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.3335</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5172</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.2929</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>0.2425</td>\n",
       "      <td>0.1711</td>\n",
       "      <td>0.1462</td>\n",
       "      <td>0.1462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3243</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.5431</td>\n",
       "      <td>0.1873</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0811</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.1786</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>0.1903</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0458</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0727</td>\n",
       "      <td>0.2593</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6180</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0431</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3072</td>\n",
       "      <td>0.4720</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0337</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.2234</td>\n",
       "      <td>0.0677</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.0815</td>\n",
       "      <td>0.0988</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0662</td>\n",
       "      <td>0.0840</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0943</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.5837</td>\n",
       "      <td>0.9935</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.2586</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>5,296,902.8823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30474</th>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.2208</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.3062</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.1673</td>\n",
       "      <td>0.1024</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.0964</td>\n",
       "      <td>0.0964</td>\n",
       "      <td>0.1096</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.1185</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.1012</td>\n",
       "      <td>0.2470</td>\n",
       "      <td>0.4165</td>\n",
       "      <td>0.4165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4163</td>\n",
       "      <td>0.0533</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4689</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2882</td>\n",
       "      <td>0.0511</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.5846</td>\n",
       "      <td>0.9939</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.3331</td>\n",
       "      <td>0.3632</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>6,468,951.2184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30475</th>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.2208</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.5810</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.1673</td>\n",
       "      <td>0.1024</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0964</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.3489</td>\n",
       "      <td>0.3243</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5127</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0541</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.2449</td>\n",
       "      <td>0.2619</td>\n",
       "      <td>0.2554</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5607</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4462</td>\n",
       "      <td>0.2381</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.5825</td>\n",
       "      <td>0.9894</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.7023</td>\n",
       "      <td>0.3214</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>5,483,527.7827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30476</th>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.3549</td>\n",
       "      <td>0.4017</td>\n",
       "      <td>0.4572</td>\n",
       "      <td>0.1957</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.3846</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1454</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2609</td>\n",
       "      <td>0.0426</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1966</td>\n",
       "      <td>0.1947</td>\n",
       "      <td>0.1986</td>\n",
       "      <td>0.3976</td>\n",
       "      <td>0.4815</td>\n",
       "      <td>0.3160</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>0.2373</td>\n",
       "      <td>0.2933</td>\n",
       "      <td>0.1957</td>\n",
       "      <td>0.1918</td>\n",
       "      <td>0.1999</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.1947</td>\n",
       "      <td>0.1987</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2006</td>\n",
       "      <td>0.1963</td>\n",
       "      <td>0.1928</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.2560</td>\n",
       "      <td>0.0551</td>\n",
       "      <td>0.1751</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.2118</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.0283</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.1994</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>0.2104</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1892</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1578</td>\n",
       "      <td>0.6733</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.5540</td>\n",
       "      <td>0.2703</td>\n",
       "      <td>0.2629</td>\n",
       "      <td>0.0404</td>\n",
       "      <td>0.3189</td>\n",
       "      <td>0.3294</td>\n",
       "      <td>0.3253</td>\n",
       "      <td>0.0429</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0573</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.2963</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1811</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>0.5254</td>\n",
       "      <td>0.2424</td>\n",
       "      <td>0.4152</td>\n",
       "      <td>0.0865</td>\n",
       "      <td>0.1092</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0.1165</td>\n",
       "      <td>0.0885</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0471</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1685</td>\n",
       "      <td>0.4102</td>\n",
       "      <td>0.2142</td>\n",
       "      <td>0.3911</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4965</td>\n",
       "      <td>0.2291</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>0.1785</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>0.2626</td>\n",
       "      <td>0.3878</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1523</td>\n",
       "      <td>0.1680</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1226</td>\n",
       "      <td>0.5642</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.5839</td>\n",
       "      <td>0.9937</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.5676</td>\n",
       "      <td>0.4846</td>\n",
       "      <td>0.0964</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>9,084,823.4039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30477</th>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.1948</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.4546</td>\n",
       "      <td>0.0963</td>\n",
       "      <td>0.7112</td>\n",
       "      <td>0.4287</td>\n",
       "      <td>0.3315</td>\n",
       "      <td>0.3846</td>\n",
       "      <td>0.3646</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1547</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2174</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3948</td>\n",
       "      <td>0.3776</td>\n",
       "      <td>0.4131</td>\n",
       "      <td>0.4616</td>\n",
       "      <td>0.4733</td>\n",
       "      <td>0.4503</td>\n",
       "      <td>0.3843</td>\n",
       "      <td>0.3151</td>\n",
       "      <td>0.4197</td>\n",
       "      <td>0.4287</td>\n",
       "      <td>0.3999</td>\n",
       "      <td>0.4597</td>\n",
       "      <td>0.3646</td>\n",
       "      <td>0.3560</td>\n",
       "      <td>0.3736</td>\n",
       "      <td>0.3909</td>\n",
       "      <td>0.3755</td>\n",
       "      <td>0.4072</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.3798</td>\n",
       "      <td>0.4185</td>\n",
       "      <td>0.4762</td>\n",
       "      <td>0.1898</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.4759</td>\n",
       "      <td>0.0620</td>\n",
       "      <td>0.3290</td>\n",
       "      <td>0.0544</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.3345</td>\n",
       "      <td>0.2631</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0811</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.2884</td>\n",
       "      <td>0.4772</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.1351</td>\n",
       "      <td>0.0471</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.1929</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1973</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.0741</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3412</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.1061</td>\n",
       "      <td>0.1109</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.4268</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0307</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1032</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0331</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0283</td>\n",
       "      <td>0.0780</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.5839</td>\n",
       "      <td>0.9937</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.6719</td>\n",
       "      <td>0.2395</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>4,750,990.7042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30478</th>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1121</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3568</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>0.3171</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.3928</td>\n",
       "      <td>0.1383</td>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.0281</td>\n",
       "      <td>0.0301</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0246</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.1673</td>\n",
       "      <td>0.1024</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0868</td>\n",
       "      <td>0.0868</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>0.0658</td>\n",
       "      <td>0.0680</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.1435</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.4931</td>\n",
       "      <td>0.4931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4942</td>\n",
       "      <td>0.1061</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1438</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3860</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4051</td>\n",
       "      <td>0.3929</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0732</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.5839</td>\n",
       "      <td>0.9937</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.4895</td>\n",
       "      <td>0.2961</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>4,543,831.1202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30479</th>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.1169</td>\n",
       "      <td>0.0948</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.0755</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>0.0927</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.0654</td>\n",
       "      <td>0.0642</td>\n",
       "      <td>0.0741</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>0.0717</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0795</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.0645</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0.0659</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.3825</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>0.7338</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1032</td>\n",
       "      <td>0.0699</td>\n",
       "      <td>0.0883</td>\n",
       "      <td>0.0883</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.1502</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.1121</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>0.3474</td>\n",
       "      <td>0.0932</td>\n",
       "      <td>0.0932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4290</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1747</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5162</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5666</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.5838</td>\n",
       "      <td>0.9934</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.3672</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>4,998,630.5895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30480</th>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.5810</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.1673</td>\n",
       "      <td>0.1024</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>0.1679</td>\n",
       "      <td>0.1228</td>\n",
       "      <td>0.0718</td>\n",
       "      <td>0.0718</td>\n",
       "      <td>0.0847</td>\n",
       "      <td>0.0456</td>\n",
       "      <td>0.1453</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1166</td>\n",
       "      <td>0.3946</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6516</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2073</td>\n",
       "      <td>0.2207</td>\n",
       "      <td>0.2151</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3716</td>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.5825</td>\n",
       "      <td>0.9894</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.7023</td>\n",
       "      <td>0.3214</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>5,292,979.0400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       full_sq  life_sq  floor  max_floor  material  num_room  state  \\\n",
       "30471   0.0071   0.0028 0.0260     0.0690    0.0000    0.0000 0.6667   \n",
       "30472   0.0147   0.0040 0.1039     0.1379    0.0000    0.1111 0.0000   \n",
       "30473   0.0074   0.0034 0.0390     0.0345    0.2000    0.0556 0.3333   \n",
       "30474   0.0116   0.0048 0.2208     0.1379    0.0000    0.0556 0.6667   \n",
       "30475   0.0073   0.0053 0.2208     0.1379    0.0000    0.0000 0.0000   \n",
       "30476   0.0089   0.0040 0.2727     0.0000    0.0000    0.0000 0.0000   \n",
       "30477   0.0071   0.0040 0.1948     0.1379    0.0000    0.0000 0.0000   \n",
       "30478   0.0079   0.0040 0.0649     0.1121    0.0000    0.0000 0.3568   \n",
       "30479   0.0083   0.0038 0.1169     0.0948    0.8000    0.0556 0.3333   \n",
       "30480   0.0079   0.0058 0.0909     0.1810    0.0000    0.0000 0.0000   \n",
       "\n",
       "       product_type  sub_area  area_m  raion_popul  green_zone_part  \\\n",
       "30471             0        38  0.1180       0.7174           0.1598   \n",
       "30472             1       103  0.1150       0.0059           0.5810   \n",
       "30473             0        84  0.0386       0.5584           0.0746   \n",
       "30474             1       105  0.0952       0.0187           0.3062   \n",
       "30475             1       103  0.1150       0.0059           0.5810   \n",
       "30476             1        24  0.0370       0.3549           0.4017   \n",
       "30477             1       124  0.0453       0.4546           0.0963   \n",
       "30478             1       102  0.3171       0.0286           0.3928   \n",
       "30479             0       136  0.0649       0.0755           0.0584   \n",
       "30480             1       103  0.1150       0.0059           0.5810   \n",
       "\n",
       "       indust_part  children_preschool  preschool_quota  \\\n",
       "30471       0.0788              0.7300           1.0000   \n",
       "30472       0.0136              0.0052           0.2416   \n",
       "30473       0.4327              0.3268           0.1872   \n",
       "30474       0.0338              0.0165           0.2416   \n",
       "30475       0.0136              0.0052           0.2416   \n",
       "30476       0.4572              0.1957           0.1276   \n",
       "30477       0.7112              0.4287           0.3315   \n",
       "30478       0.1383              0.0253           0.2416   \n",
       "30479       0.0695              0.0691           0.0927   \n",
       "30480       0.0136              0.0052           0.2416   \n",
       "\n",
       "       preschool_education_centers_raion  children_school  \\\n",
       "30471                             0.8462           0.7784   \n",
       "30472                             0.0000           0.0051   \n",
       "30473                             0.5385           0.3378   \n",
       "30474                             0.0000           0.0159   \n",
       "30475                             0.0000           0.0051   \n",
       "30476                             0.3846           0.1967   \n",
       "30477                             0.3846           0.3646   \n",
       "30478                             0.0000           0.0244   \n",
       "30479                             0.0769           0.0608   \n",
       "30480                             0.0000           0.0051   \n",
       "\n",
       "       school_education_centers_raion  school_education_centers_top_20_raion  \\\n",
       "30471                          0.9286                                 0.5000   \n",
       "30472                          0.0000                                 0.0000   \n",
       "30473                          0.5000                                 0.0000   \n",
       "30474                          0.0000                                 0.0000   \n",
       "30475                          0.0000                                 0.0000   \n",
       "30476                          0.3571                                 0.0000   \n",
       "30477                          0.3571                                 0.0000   \n",
       "30478                          0.0000                                 0.0000   \n",
       "30479                          0.0714                                 0.0000   \n",
       "30480                          0.0000                                 0.0000   \n",
       "\n",
       "       hospital_beds_raion  healthcare_centers_raion  university_top_20_raion  \\\n",
       "30471               0.2462                    0.1667                   0.0000   \n",
       "30472               0.2462                    0.0000                   0.0000   \n",
       "30473               0.3192                    0.5000                   0.0000   \n",
       "30474               0.2462                    0.0000                   0.0000   \n",
       "30475               0.2462                    0.0000                   0.0000   \n",
       "30476               0.1454                    0.5000                   0.0000   \n",
       "30477               0.1547                    0.3333                   0.0000   \n",
       "30478               0.2462                    0.0000                   0.0000   \n",
       "30479               0.0412                    0.1667                   0.0000   \n",
       "30480               0.2462                    0.0000                   0.0000   \n",
       "\n",
       "       sport_objects_raion  additional_education_raion  \\\n",
       "30471               0.4483                      0.2500   \n",
       "30472               0.0000                      0.0000   \n",
       "30473               0.4483                      0.0000   \n",
       "30474               0.0000                      0.1250   \n",
       "30475               0.0000                      0.0000   \n",
       "30476               0.6207                      0.0625   \n",
       "30477               0.1379                      0.1875   \n",
       "30478               0.0345                      0.0000   \n",
       "30479               0.0000                      0.0000   \n",
       "30480               0.0000                      0.0000   \n",
       "\n",
       "       culture_objects_top_25  shopping_centers_raion  office_raion  \\\n",
       "30471                       0                  0.1739        0.0284   \n",
       "30472                       0                  0.0435        0.0000   \n",
       "30473                       0                  0.0870        0.0496   \n",
       "30474                       0                  0.0000        0.0000   \n",
       "30475                       0                  0.0435        0.0000   \n",
       "30476                       0                  0.2609        0.0426   \n",
       "30477                       0                  0.2174        0.0071   \n",
       "30478                       0                  0.0000        0.0071   \n",
       "30479                       0                  0.0435        0.0071   \n",
       "30480                       0                  0.0435        0.0000   \n",
       "\n",
       "       thermal_power_plant_raion  incineration_raion  oil_chemistry_raion  \\\n",
       "30471                          0                   0                    0   \n",
       "30472                          0                   0                    0   \n",
       "30473                          1                   0                    1   \n",
       "30474                          0                   0                    0   \n",
       "30475                          0                   0                    0   \n",
       "30476                          0                   0                    0   \n",
       "30477                          0                   0                    0   \n",
       "30478                          0                   0                    0   \n",
       "30479                          0                   0                    0   \n",
       "30480                          0                   0                    0   \n",
       "\n",
       "       radiation_raion  railroad_terminal_raion  big_market_raion  \\\n",
       "30471                0                        0                 0   \n",
       "30472                0                        0                 0   \n",
       "30473                1                        0                 0   \n",
       "30474                0                        0                 0   \n",
       "30475                0                        0                 0   \n",
       "30476                1                        0                 0   \n",
       "30477                0                        0                 0   \n",
       "30478                0                        0                 1   \n",
       "30479                0                        0                 0   \n",
       "30480                0                        0                 0   \n",
       "\n",
       "       nuclear_reactor_raion  detention_facility_raion  young_all  young_male  \\\n",
       "30471                      0                         0     0.7549      0.7727   \n",
       "30472                      0                         0     0.0052      0.0052   \n",
       "30473                      0                         0     0.3331      0.3246   \n",
       "30474                      0                         0     0.0163      0.0164   \n",
       "30475                      0                         0     0.0052      0.0052   \n",
       "30476                      0                         0     0.1966      0.1947   \n",
       "30477                      0                         0     0.3948      0.3776   \n",
       "30478                      0                         0     0.0249      0.0250   \n",
       "30479                      0                         0     0.0649      0.0654   \n",
       "30480                      0                         0     0.0052      0.0052   \n",
       "\n",
       "       young_female  work_all  work_male  work_female  ekder_all  ekder_male  \\\n",
       "30471        0.7360    0.7500     0.7399       0.7597     0.4517      0.3794   \n",
       "30472        0.0051    0.0058     0.0063       0.0054     0.0055      0.0046   \n",
       "30473        0.3422    0.5647     0.5570       0.5722     0.5869      0.4967   \n",
       "30474        0.0162    0.0184     0.0197       0.0171     0.0174      0.0146   \n",
       "30475        0.0051    0.0058     0.0063       0.0054     0.0055      0.0046   \n",
       "30476        0.1986    0.3976     0.4815       0.3160     0.2743      0.2373   \n",
       "30477        0.4131    0.4616     0.4733       0.4503     0.3843      0.3151   \n",
       "30478        0.0248    0.0281     0.0301       0.0262     0.0267      0.0223   \n",
       "30479        0.0642    0.0741     0.0771       0.0711     0.0717      0.0564   \n",
       "30480        0.0051    0.0058     0.0063       0.0054     0.0055      0.0046   \n",
       "\n",
       "       ekder_female  0_6_all  0_6_male  0_6_female  7_14_all  7_14_male  \\\n",
       "30471        0.4886   0.7300    0.7443      0.7145    0.7784     0.8013   \n",
       "30472        0.0060   0.0052    0.0053      0.0052    0.0051     0.0051   \n",
       "30473        0.6329   0.3268    0.3151      0.3394    0.3378     0.3339   \n",
       "30474        0.0189   0.0165    0.0165      0.0165    0.0159     0.0160   \n",
       "30475        0.0060   0.0052    0.0053      0.0052    0.0051     0.0051   \n",
       "30476        0.2933   0.1957    0.1918      0.1999    0.1967     0.1947   \n",
       "30477        0.4197   0.4287    0.3999      0.4597    0.3646     0.3560   \n",
       "30478        0.0289   0.0253    0.0252      0.0252    0.0244     0.0246   \n",
       "30479        0.0795   0.0691    0.0694      0.0686    0.0608     0.0618   \n",
       "30480        0.0060   0.0052    0.0053      0.0052    0.0051     0.0051   \n",
       "\n",
       "       7_14_female  0_17_all  0_17_male  0_17_female  0_13_all  0_13_male  \\\n",
       "30471       0.7544    0.7581     0.7767       0.7383    0.7505     0.7700   \n",
       "30472       0.0050    0.0053     0.0053       0.0052    0.0052     0.0052   \n",
       "30473       0.3419    0.3374     0.3301       0.3451    0.3315     0.3233   \n",
       "30474       0.0158    0.0165     0.0166       0.0163    0.0162     0.0162   \n",
       "30475       0.0050    0.0053     0.0053       0.0052    0.0052     0.0052   \n",
       "30476       0.1987    0.1975     0.1945       0.2006    0.1963     0.1928   \n",
       "30477       0.3736    0.3909     0.3755       0.4072    0.3985     0.3798   \n",
       "30478       0.0241    0.0253     0.0255       0.0250    0.0248     0.0248   \n",
       "30479       0.0596    0.0647     0.0645       0.0649    0.0650     0.0659   \n",
       "30480       0.0050    0.0053     0.0053       0.0052    0.0052     0.0052   \n",
       "\n",
       "       0_13_female  raion_build_count_with_material_info  build_count_brick  \\\n",
       "30471       0.7297                                1.0000             0.3690   \n",
       "30472       0.0051                                0.1673             0.1024   \n",
       "30473       0.3403                                0.3333             0.3825   \n",
       "30474       0.0161                                0.1673             0.1024   \n",
       "30475       0.0051                                0.1673             0.1024   \n",
       "30476       0.2000                                0.1750             0.2560   \n",
       "30477       0.4185                                0.4762             0.1898   \n",
       "30478       0.0247                                0.1673             0.1024   \n",
       "30479       0.0641                                0.7333             0.3825   \n",
       "30480       0.0051                                0.1673             0.1024   \n",
       "\n",
       "       build_count_monolith  raion_build_count_with_builddate_info  \\\n",
       "30471                0.9134                                 1.0000   \n",
       "30472                0.0472                                 0.1674   \n",
       "30473                0.0236                                 0.3335   \n",
       "30474                0.0472                                 0.1674   \n",
       "30475                0.0472                                 0.1674   \n",
       "30476                0.0551                                 0.1751   \n",
       "30477                0.1260                                 0.4759   \n",
       "30478                0.0472                                 0.1674   \n",
       "30479                0.1417                                 0.7338   \n",
       "30480                0.0472                                 0.1674   \n",
       "\n",
       "       build_count_before_1920  build_count_1946-1970  metro_min_avto  \\\n",
       "30471                   0.0916                 0.5195          0.0205   \n",
       "30472                   0.0000                 0.1645          0.0689   \n",
       "30473                   0.0000                 0.5172          0.0258   \n",
       "30474                   0.0000                 0.1645          0.1291   \n",
       "30475                   0.0000                 0.1645          0.0350   \n",
       "30476                   0.0027                 0.2118          0.0550   \n",
       "30477                   0.0620                 0.3290          0.0544   \n",
       "30478                   0.0000                 0.1645          0.1008   \n",
       "30479                   0.0027                 1.0000          0.1032   \n",
       "30480                   0.0000                 0.1645          0.1679   \n",
       "\n",
       "       metro_km_avto  metro_min_walk  metro_km_walk  kindergarten_km  \\\n",
       "30471         0.0098          0.0124         0.0124           0.0027   \n",
       "30472         0.0460          0.0581         0.0581           0.0410   \n",
       "30473         0.0150          0.0189         0.0189           0.0022   \n",
       "30474         0.0806          0.0964         0.0964           0.1096   \n",
       "30475         0.0230          0.0291         0.0291           0.0309   \n",
       "30476         0.0283          0.0352         0.0352           0.0250   \n",
       "30477         0.0272          0.0344         0.0344           0.0079   \n",
       "30478         0.0687          0.0868         0.0868           0.1025   \n",
       "30479         0.0699          0.0883         0.0883           0.0442   \n",
       "30480         0.1228          0.0718         0.0718           0.0847   \n",
       "\n",
       "       school_km  park_km  green_zone_km  industrial_km  water_treatment_km  \\\n",
       "30471     0.0158   0.0432         0.0310         0.0858              0.0147   \n",
       "30472     0.0281   0.0929         0.0000         0.0528              0.3334   \n",
       "30473     0.0041   0.0530         0.2929         0.0641              0.2425   \n",
       "30474     0.0747   0.1185         0.0128         0.0332              0.1012   \n",
       "30475     0.0260   0.0964         0.2155         0.0252              0.3489   \n",
       "30476     0.0226   0.0362         0.1994         0.0000              0.3048   \n",
       "30477     0.0009   0.0131         0.1818         0.0449              0.3345   \n",
       "30478     0.0658   0.0680         0.0565         0.0060              0.1435   \n",
       "30479     0.0178   0.1502         0.0197         0.1121              0.3460   \n",
       "30480     0.0456   0.1453         0.0000         0.1166              0.3946   \n",
       "\n",
       "       incineration_km  railroad_station_walk_km  railroad_station_walk_min  \\\n",
       "30471           0.1774                    0.1943                     0.1943   \n",
       "30472           0.3132                    0.2205                     0.2205   \n",
       "30473           0.1711                    0.1462                     0.1462   \n",
       "30474           0.2470                    0.4165                     0.4165   \n",
       "30475           0.3243                    0.1506                     0.1506   \n",
       "30476           0.2104                    0.1154                     0.1154   \n",
       "30477           0.2631                    0.0920                     0.0920   \n",
       "30478           0.1695                    0.4931                     0.4931   \n",
       "30479           0.3474                    0.0932                     0.0932   \n",
       "30480           0.3706                    0.0995                     0.0995   \n",
       "\n",
       "       ...  sport_count_1500  market_count_1500  green_part_2000  \\\n",
       "30471  ...            0.1081             0.0000           0.2014   \n",
       "30472  ...            0.0270             0.0000           0.6541   \n",
       "30473  ...            0.3243             0.4286           0.5431   \n",
       "30474  ...            0.0000             0.0000           0.4163   \n",
       "30475  ...            0.0000             0.0000           0.5127   \n",
       "30476  ...            0.1892             0.0000           0.1578   \n",
       "30477  ...            0.0811             0.2857           0.2884   \n",
       "30478  ...            0.0270             0.0000           0.4942   \n",
       "30479  ...            0.0000             0.0000           0.4290   \n",
       "30480  ...            0.0000             0.0000           0.6516   \n",
       "\n",
       "       prom_part_2000  office_count_2000  office_sqm_2000  trc_count_2000  \\\n",
       "30471          0.0210             0.0000           0.0000          0.0000   \n",
       "30472          0.0724             0.0000           0.0000          0.0270   \n",
       "30473          0.1873             0.0240           0.0223          0.0811   \n",
       "30474          0.0533             0.0000           0.0000          0.0000   \n",
       "30475          0.0556             0.0000           0.0000          0.0541   \n",
       "30476          0.6733             0.1120           0.5540          0.2703   \n",
       "30477          0.4772             0.0080           0.0219          0.1351   \n",
       "30478          0.1061             0.0000           0.0000          0.0000   \n",
       "30479          0.0025             0.0000           0.0000          0.0270   \n",
       "30480          0.0036             0.0000           0.0000          0.0270   \n",
       "\n",
       "       trc_sqm_2000  cafe_count_2000  cafe_sum_2000_min_price_avg  \\\n",
       "30471        0.0000           0.0027                       0.3750   \n",
       "30472        0.0020           0.0063                       0.2449   \n",
       "30473        0.0058           0.0251                       0.1786   \n",
       "30474        0.0000           0.0009                       0.0000   \n",
       "30475        0.0090           0.0063                       0.2449   \n",
       "30476        0.2629           0.0404                       0.3189   \n",
       "30477        0.0471           0.0063                       0.1929   \n",
       "30478        0.0000           0.0009                       0.1071   \n",
       "30479        0.0069           0.0018                       0.1875   \n",
       "30480        0.0069           0.0000                       0.2073   \n",
       "\n",
       "       cafe_sum_2000_max_price_avg  cafe_avg_price_2000  \\\n",
       "30471                       0.3333               0.3493   \n",
       "30472                       0.2619               0.2554   \n",
       "30473                       0.1975               0.1903   \n",
       "30474                       0.0000               0.0000   \n",
       "30475                       0.2619               0.2554   \n",
       "30476                       0.3294               0.3253   \n",
       "30477                       0.2000               0.1973   \n",
       "30478                       0.1667               0.1438   \n",
       "30479                       0.1667               0.1747   \n",
       "30480                       0.2207               0.2151   \n",
       "\n",
       "       cafe_count_2000_na_price  cafe_count_2000_price_500  \\\n",
       "30471                    0.0000                     0.0000   \n",
       "30472                    0.0000                     0.0036   \n",
       "30473                    0.0143                     0.0252   \n",
       "30474                    0.0000                     0.0036   \n",
       "30475                    0.0000                     0.0036   \n",
       "30476                    0.0429                     0.0252   \n",
       "30477                    0.0286                     0.0036   \n",
       "30478                    0.0000                     0.0000   \n",
       "30479                    0.0000                     0.0036   \n",
       "30480                    0.0000                     0.0000   \n",
       "\n",
       "       cafe_count_2000_price_1000  cafe_count_2000_price_1500  \\\n",
       "30471                      0.0000                      0.0115   \n",
       "30472                      0.0115                      0.0077   \n",
       "30473                      0.0458                      0.0230   \n",
       "30474                      0.0000                      0.0000   \n",
       "30475                      0.0115                      0.0077   \n",
       "30476                      0.0573                      0.0421   \n",
       "30477                      0.0076                      0.0077   \n",
       "30478                      0.0038                      0.0000   \n",
       "30479                      0.0000                      0.0038   \n",
       "30480                      0.0000                      0.0000   \n",
       "\n",
       "       cafe_count_2000_price_2500  cafe_count_2000_price_4000  \\\n",
       "30471                      0.0000                      0.0000   \n",
       "30472                      0.0059                      0.0000   \n",
       "30473                      0.0118                      0.0000   \n",
       "30474                      0.0000                      0.0000   \n",
       "30475                      0.0059                      0.0000   \n",
       "30476                      0.0412                      0.0123   \n",
       "30477                      0.0000                      0.0000   \n",
       "30478                      0.0000                      0.0000   \n",
       "30479                      0.0000                      0.0000   \n",
       "30480                      0.0000                      0.0000   \n",
       "\n",
       "       cafe_count_2000_price_high  big_church_count_2000  church_count_2000  \\\n",
       "30471                      0.0000                 0.0143             0.0185   \n",
       "30472                      0.0000                 0.0143             0.0185   \n",
       "30473                      0.0000                 0.0286             0.0185   \n",
       "30474                      0.0000                 0.0000             0.0278   \n",
       "30475                      0.0000                 0.0143             0.0185   \n",
       "30476                      0.0625                 0.0143             0.0185   \n",
       "30477                      0.0000                 0.0000             0.0000   \n",
       "30478                      0.0000                 0.0000             0.0185   \n",
       "30479                      0.0000                 0.0000             0.0093   \n",
       "30480                      0.0000                 0.0000             0.0185   \n",
       "\n",
       "       mosque_count_2000  leisure_count_2000  sport_count_2000  \\\n",
       "30471             1.0000              0.0000            0.0926   \n",
       "30472             0.0000              0.0000            0.0185   \n",
       "30473             0.0000              0.0727            0.2593   \n",
       "30474             0.0000              0.0000            0.0000   \n",
       "30475             0.0000              0.0000            0.0556   \n",
       "30476             0.0000              0.0182            0.2963   \n",
       "30477             0.0000              0.0182            0.0741   \n",
       "30478             0.0000              0.0000            0.0185   \n",
       "30479             0.0000              0.0000            0.0000   \n",
       "30480             0.0000              0.0000            0.0000   \n",
       "\n",
       "       market_count_2000  green_part_3000  office_count_3000  office_sqm_3000  \\\n",
       "30471             0.0000           0.1951             0.0000           0.0000   \n",
       "30472             0.0000           0.5317             0.0000           0.0000   \n",
       "30473             0.5000           0.6180             0.0162           0.0352   \n",
       "30474             0.0000           0.4689             0.0000           0.0000   \n",
       "30475             0.0000           0.5607             0.0000           0.0000   \n",
       "30476             0.0000           0.1811             0.1055           0.5254   \n",
       "30477             0.2500           0.3412             0.0061           0.0300   \n",
       "30478             0.0000           0.3860             0.0020           0.0139   \n",
       "30479             0.0000           0.5162             0.0000           0.0000   \n",
       "30480             0.0000           0.5238             0.0000           0.0000   \n",
       "\n",
       "       trc_count_3000  trc_sqm_3000  cafe_count_3000  \\\n",
       "30471          0.0455        0.0275           0.0066   \n",
       "30472          0.0303        0.0083           0.0055   \n",
       "30473          0.0909        0.0147           0.0204   \n",
       "30474          0.0000        0.0000           0.0006   \n",
       "30475          0.0303        0.0083           0.0050   \n",
       "30476          0.2424        0.4152           0.0865   \n",
       "30477          0.1061        0.1109           0.0066   \n",
       "30478          0.0000        0.0000           0.0022   \n",
       "30479          0.0152        0.0064           0.0028   \n",
       "30480          0.0152        0.0064           0.0022   \n",
       "\n",
       "       cafe_count_3000_na_price  cafe_count_3000_price_500  \\\n",
       "30471                    0.0084                     0.0045   \n",
       "30472                    0.0000                     0.0022   \n",
       "30473                    0.0084                     0.0178   \n",
       "30474                    0.0000                     0.0022   \n",
       "30475                    0.0000                     0.0022   \n",
       "30476                    0.1092                     0.0757   \n",
       "30477                    0.0252                     0.0045   \n",
       "30478                    0.0000                     0.0000   \n",
       "30479                    0.0000                     0.0022   \n",
       "30480                    0.0000                     0.0022   \n",
       "\n",
       "       cafe_count_3000_price_1000  cafe_count_3000_price_1500  \\\n",
       "30471                      0.0045                      0.0157   \n",
       "30472                      0.0136                      0.0045   \n",
       "30473                      0.0431                      0.0157   \n",
       "30474                      0.0000                      0.0000   \n",
       "30475                      0.0113                      0.0045   \n",
       "30476                      0.0884                      0.0650   \n",
       "30477                      0.0113                      0.0045   \n",
       "30478                      0.0023                      0.0022   \n",
       "30479                      0.0045                      0.0022   \n",
       "30480                      0.0023                      0.0022   \n",
       "\n",
       "       cafe_count_3000_price_2500  cafe_count_3000_price_4000  \\\n",
       "30471                      0.0000                      0.0000   \n",
       "30472                      0.0038                      0.0000   \n",
       "30473                      0.0075                      0.0000   \n",
       "30474                      0.0000                      0.0000   \n",
       "30475                      0.0038                      0.0000   \n",
       "30476                      0.1165                      0.0885   \n",
       "30477                      0.0000                      0.0000   \n",
       "30478                      0.0038                      0.0088   \n",
       "30479                      0.0038                      0.0000   \n",
       "30480                      0.0038                      0.0000   \n",
       "\n",
       "       cafe_count_3000_price_high  big_church_count_3000  church_count_3000  \\\n",
       "30471                      0.0000                 0.0098             0.0183   \n",
       "30472                      0.0000                 0.0098             0.0305   \n",
       "30473                      0.0000                 0.0196             0.0183   \n",
       "30474                      0.0000                 0.0000             0.0244   \n",
       "30475                      0.0000                 0.0098             0.0244   \n",
       "30476                      0.0435                 0.0294             0.0549   \n",
       "30477                      0.0000                 0.0000             0.0183   \n",
       "30478                      0.0000                 0.0000             0.0244   \n",
       "30479                      0.0000                 0.0000             0.0122   \n",
       "30480                      0.0000                 0.0000             0.0183   \n",
       "\n",
       "       mosque_count_3000  leisure_count_3000  sport_count_3000  \\\n",
       "30471             0.5000              0.0000            0.0700   \n",
       "30472             0.0000              0.0000            0.0700   \n",
       "30473             0.0000              0.0588            0.2200   \n",
       "30474             0.0000              0.0000            0.0000   \n",
       "30475             0.0000              0.0000            0.0600   \n",
       "30476             0.0000              0.0471            0.3600   \n",
       "30477             0.0000              0.0118            0.0500   \n",
       "30478             0.0000              0.0000            0.0100   \n",
       "30479             0.0000              0.0000            0.0000   \n",
       "30480             0.0000              0.0000            0.0000   \n",
       "\n",
       "       market_count_3000  green_part_5000  prom_part_5000  office_count_5000  \\\n",
       "30471             0.0000           0.2510          0.1580             0.0013   \n",
       "30472             0.0000           0.4946          0.2642             0.0025   \n",
       "30473             0.4000           0.3072          0.4720             0.0342   \n",
       "30474             0.0000           0.2882          0.0511             0.0000   \n",
       "30475             0.0000           0.4462          0.2381             0.0013   \n",
       "30476             0.2000           0.1685          0.4102             0.2142   \n",
       "30477             0.2000           0.3140          0.4268             0.0139   \n",
       "30478             0.0000           0.4051          0.3929             0.0038   \n",
       "30479             0.0000           0.5666          0.1249             0.0013   \n",
       "30480             0.0000           0.3716          0.0480             0.0000   \n",
       "\n",
       "       office_sqm_5000  trc_count_5000  trc_sqm_5000  cafe_count_5000  \\\n",
       "30471           0.0030          0.0667        0.0652           0.0072   \n",
       "30472           0.0140          0.0500        0.0504           0.0076   \n",
       "30473           0.0337          0.2167        0.2234           0.0677   \n",
       "30474           0.0000          0.0000        0.0000           0.0019   \n",
       "30475           0.0092          0.0333        0.0439           0.0076   \n",
       "30476           0.3911          0.3333        0.4965           0.2291   \n",
       "30477           0.0307          0.1250        0.1032           0.0197   \n",
       "30478           0.0086          0.0333        0.0732           0.0098   \n",
       "30479           0.0092          0.0250        0.0304           0.0049   \n",
       "30480           0.0000          0.0167        0.0048           0.0068   \n",
       "\n",
       "       cafe_count_5000_na_price  cafe_count_5000_price_500  \\\n",
       "30471                    0.0115                     0.0077   \n",
       "30472                    0.0115                     0.0062   \n",
       "30473                    0.0287                     0.0815   \n",
       "30474                    0.0000                     0.0015   \n",
       "30475                    0.0057                     0.0062   \n",
       "30476                    0.2529                     0.1785   \n",
       "30477                    0.0345                     0.0169   \n",
       "30478                    0.0057                     0.0154   \n",
       "30479                    0.0057                     0.0031   \n",
       "30480                    0.0000                     0.0031   \n",
       "\n",
       "       cafe_count_5000_price_1000  cafe_count_5000_price_1500  \\\n",
       "30471                      0.0062                      0.0125   \n",
       "30472                      0.0123                      0.0062   \n",
       "30473                      0.0988                      0.0655   \n",
       "30474                      0.0000                      0.0016   \n",
       "30475                      0.0123                      0.0078   \n",
       "30476                      0.2083                      0.2231   \n",
       "30477                      0.0216                      0.0187   \n",
       "30478                      0.0093                      0.0078   \n",
       "30479                      0.0093                      0.0047   \n",
       "30480                      0.0123                      0.0078   \n",
       "\n",
       "       cafe_count_5000_price_2500  cafe_count_5000_price_4000  \\\n",
       "30471                      0.0000                      0.0000   \n",
       "30472                      0.0027                      0.0068   \n",
       "30473                      0.0292                      0.0272   \n",
       "30474                      0.0027                      0.0136   \n",
       "30475                      0.0027                      0.0068   \n",
       "30476                      0.2626                      0.3878   \n",
       "30477                      0.0186                      0.0136   \n",
       "30478                      0.0053                      0.0136   \n",
       "30479                      0.0027                      0.0000   \n",
       "30480                      0.0053                      0.0068   \n",
       "\n",
       "       cafe_count_5000_price_high  big_church_count_5000  church_count_5000  \\\n",
       "30471                      0.0000                 0.0066             0.0400   \n",
       "30472                      0.0000                 0.0132             0.0440   \n",
       "30473                      0.0000                 0.0662             0.0840   \n",
       "30474                      0.0000                 0.0000             0.0400   \n",
       "30475                      0.0000                 0.0132             0.0480   \n",
       "30476                      0.4000                 0.1523             0.1680   \n",
       "30477                      0.0000                 0.0331             0.0560   \n",
       "30478                      0.0000                 0.0199             0.0480   \n",
       "30479                      0.0000                 0.0066             0.0280   \n",
       "30480                      0.0000                 0.0132             0.0360   \n",
       "\n",
       "       mosque_count_5000  leisure_count_5000  sport_count_5000  \\\n",
       "30471             0.5000              0.0000            0.0642   \n",
       "30472             0.0000              0.0094            0.0550   \n",
       "30473             0.0000              0.0943            0.3257   \n",
       "30474             0.0000              0.0000            0.0092   \n",
       "30475             0.0000              0.0094            0.0505   \n",
       "30476             0.5000              0.1226            0.5642   \n",
       "30477             0.0000              0.0283            0.0780   \n",
       "30478             0.0000              0.0000            0.0275   \n",
       "30479             0.0000              0.0000            0.0321   \n",
       "30480             0.0000              0.0000            0.0321   \n",
       "\n",
       "       market_count_5000   year  year_month  living_area_ratio  \\\n",
       "30471             0.0476 1.0000          47             0.0056   \n",
       "30472             0.0476 1.0000          47             0.0063   \n",
       "30473             0.5238 1.0000          47             0.0065   \n",
       "30474             0.0000 1.0000          47             0.0061   \n",
       "30475             0.0476 1.0000          47             0.0106   \n",
       "30476             0.3333 1.0000          47             0.0063   \n",
       "30477             0.0952 1.0000          47             0.0063   \n",
       "30478             0.1429 1.0000          47             0.0063   \n",
       "30479             0.0000 1.0000          47             0.0066   \n",
       "30480             0.0000 1.0000          47             0.0106   \n",
       "\n",
       "       non_living_area  non_living_area_ratio  room_area_avg  relative_floor  \\\n",
       "30471           0.5839                 0.9944         0.0083          0.0060   \n",
       "30472           0.5839                 0.9937         0.0074          0.0127   \n",
       "30473           0.5837                 0.9935         0.0050          0.0162   \n",
       "30474           0.5846                 0.9939         0.0072          0.0270   \n",
       "30475           0.5825                 0.9894         0.0160          0.0270   \n",
       "30476           0.5839                 0.9937         0.0074          0.5676   \n",
       "30477           0.5839                 0.9937         0.0074          0.0238   \n",
       "30478           0.5839                 0.9937         0.0074          0.0160   \n",
       "30479           0.5838                 0.9934         0.0057          0.0203   \n",
       "30480           0.5825                 0.9894         0.0174          0.0086   \n",
       "\n",
       "       sub_area_building_height_avg  sub_area_kremlin_dist_avg  \\\n",
       "30471                        0.5248                     0.3324   \n",
       "30472                        0.7023                     0.3214   \n",
       "30473                        0.2586                     0.1357   \n",
       "30474                        0.3331                     0.3632   \n",
       "30475                        0.7023                     0.3214   \n",
       "30476                        0.4846                     0.0964   \n",
       "30477                        0.6719                     0.2395   \n",
       "30478                        0.4895                     0.2961   \n",
       "30479                        0.3672                     0.3590   \n",
       "30480                        0.7023                     0.3214   \n",
       "\n",
       "       sales_year_month      price_doc  \n",
       "30471            0.2309 5,247,336.8339  \n",
       "30472            0.2309 8,183,807.8635  \n",
       "30473            0.2309 5,296,902.8823  \n",
       "30474            0.2309 6,468,951.2184  \n",
       "30475            0.2309 5,483,527.7827  \n",
       "30476            0.2309 9,084,823.4039  \n",
       "30477            0.2309 4,750,990.7042  \n",
       "30478            0.2309 4,543,831.1202  \n",
       "30479            0.2309 4,998,630.5895  \n",
       "30480            0.2309 5,292,979.0400  \n",
       "\n",
       "[10 rows x 250 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test['price_doc'] = np.expm1(pred)\n",
    "x_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "88d0a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the test data with predicted price into the csv file\n",
    "x_test['id'] = test_id\n",
    "x_test[['id','price_doc']].to_csv('./output_models/output_custom.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da8196e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "1d649c4a-48b1-4ddf-9c6c-61154fc3eb69",
    "3fc7bc7b-a329-4d0a-8378-ecd214a94a5c",
    "f43233fd-d92c-45c3-a983-6760d17f8af2",
    "3db5652b-0e4c-4483-9ae4-c12cfc02cad9",
    "eacd3859-1644-49e7-b823-ecaa1a1e1309",
    "9fd74c3a-7d03-4ef1-88f5-512543ea2743",
    "ad7d8de9-ce0e-49ff-9182-d43884be8de9",
    "76333052-72ea-49d9-9bae-dfc14cb16a97",
    "b2c02a57-93c2-48a1-811f-a0a098007051",
    "cb448266-8c1d-43f4-a546-cd1da680cc5d",
    "e7611d91-b2bb-463f-afec-d61387c96aa9",
    "f6467dc8-edbf-42f4-a5da-2b943280d570",
    "a249ef17-e4c0-4dc6-9c37-d99bddfe4397",
    "dc7fd1ae-6b64-477d-a07d-2c39691ee4c9",
    "dfcbad98-798b-4726-9945-65f0621e9a6c",
    "13a68d3a-924b-418f-aa40-7e2d781d7cd4",
    "12015471-eacf-408c-823a-99a86a89a3f5",
    "81987137-ad1d-4c38-b4fd-5afa0d179f45",
    "5a556eaa-ce64-42cd-bc3b-012dd80e6abb"
   ],
   "name": "ExploratoryDataAnalysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
